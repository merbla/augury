{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "    \n",
    "import tensorflow.keras.backend as K\n",
    "from tensorflow.keras import callbacks\n",
    "from tensorflow.keras.preprocessing.text import one_hot\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.backend import clear_session\n",
    "from tensorflow.keras import regularizers\n",
    "\n",
    "PROJECT_PATH = os.path.abspath(os.path.join(os.getcwd(), '../'))\n",
    "\n",
    "if PROJECT_PATH not in sys.path:\n",
    "    sys.path.append(PROJECT_PATH)\n",
    "    \n",
    "from server.ml_models.avg_model.avg_model import AvgModel, ESTIMATORS\n",
    "from server.ml_models.all_model import AllModelData\n",
    "from server.ml_models.sklearn import AveragingRegressor\n",
    "from src.model.metrics import measure_estimators, yearly_performance_scores\n",
    "from src.model.charts import graph_cv_model_performance, graph_yearly_model_performance\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "class InputLister(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, n_inputs=1):\n",
    "        self.n_inputs = n_inputs\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return [X[:, n] if n < self.n_inputs - 1 else X[:, n:] for n in range(self.n_inputs)]\n",
    "    \n",
    "    \n",
    "def tip_accuracy(y, y_pred):\n",
    "    correct_preds = ((y >= 0) & (y_pred >= 0)) | ((y <= 0) & (y_pred <= 0))\n",
    "    return K.mean(correct_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Returning data from 1965-01-01 to 2016-12-31\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/usr/local/lib/python3.6/site-packages/rpy2/rinterface/__init__.py:146: RRuntimeWarning: Finished getting afltables data\n",
      "\n",
      "  warnings.warn(x, RRuntimeWarning)\n",
      "/usr/local/lib/python3.6/site-packages/rpy2/robjects/pandas2ri.py:191: FutureWarning: from_items is deprecated. Please use DataFrame.from_dict(dict(items), ...) instead. DataFrame.from_dict(OrderedDict(items)) may be used to preserve the key order.\n",
      "  res = PandasDataFrame.from_items(items)\n",
      "/app/backend/server/data_processors/feature_functions.py:476: FutureWarning: 'player_id' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  .groupby([\"player_id\", \"year\"], group_keys=True)\n",
      "/app/backend/server/data_processors/feature_functions.py:476: FutureWarning: 'year' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  .groupby([\"player_id\", \"year\"], group_keys=True)\n",
      "/app/backend/server/data_processors/feature_functions.py:486: FutureWarning: 'player_id' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  .merge(brownlow_last_year, on=[\"player_id\", \"year\"], how=\"left\")\n",
      "/app/backend/server/data_processors/feature_functions.py:486: FutureWarning: 'year' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  .merge(brownlow_last_year, on=[\"player_id\", \"year\"], how=\"left\")\n",
      "/app/backend/server/data_processors/feature_functions.py:532: FutureWarning: 'player_id' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  player_data_frame = data_frame.sort_values([\"player_id\", \"year\", \"round_number\"])\n",
      "/app/backend/server/data_processors/feature_functions.py:532: FutureWarning: 'year' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  player_data_frame = data_frame.sort_values([\"player_id\", \"year\", \"round_number\"])\n",
      "/app/backend/server/data_processors/feature_functions.py:532: FutureWarning: 'round_number' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  player_data_frame = data_frame.sort_values([\"player_id\", \"year\", \"round_number\"])\n",
      "/app/backend/server/data_processors/feature_functions.py:535: FutureWarning: 'player_id' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  .groupby(\"player_id\", group_keys=False)\n",
      "/app/backend/server/data_processors/feature_functions.py:539: FutureWarning: 'player_id' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  .groupby(\"player_id\", group_keys=False)\n",
      "/app/backend/server/data_processors/feature_functions.py:564: FutureWarning: 'player_id' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  cum_matches_played=data_frame.groupby(\"player_id\").cumcount()\n",
      "/app/backend/server/data_processors/player_data_aggregator.py:77: FutureWarning: 'team' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  .groupby(self.index_cols + [\"oppo_team\"])\n",
      "/app/backend/server/data_processors/player_data_aggregator.py:77: FutureWarning: 'year' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  .groupby(self.index_cols + [\"oppo_team\"])\n",
      "/app/backend/server/data_processors/player_data_aggregator.py:77: FutureWarning: 'round_number' is both an index level and a column label.\n",
      "Defaulting to column, but this will raise an ambiguity error in a future version\n",
      "  .groupby(self.index_cols + [\"oppo_team\"])\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "\n",
    "CATEGORY_COLS = ['team', 'oppo_team', 'round_type']\n",
    "\n",
    "data = AllModelData(train_years=(None, 2016))\n",
    "\n",
    "# Have to put categorical columns first to separate by type via index, then join after encoding the categories\n",
    "organised_cols = CATEGORY_COLS + list(set(data.data.columns) - set(CATEGORY_COLS))\n",
    "organised_cols\n",
    "\n",
    "features = data.data[organised_cols].drop(['score', 'oppo_score'], axis=1)\n",
    "labels = data.data['score'] - data.data['oppo_score']\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create basic averaging model\n",
    "\n",
    "numeric_cols = list(set(features.columns) - set(CATEGORY_COLS))\n",
    "categories = [data.data[cat_col].drop_duplicates().values for cat_col in CATEGORY_COLS]\n",
    "\n",
    "ct = ColumnTransformer(\n",
    "    [(\"onehot\", OneHotEncoder(categories=categories), CATEGORY_COLS),\n",
    "     (\"scaling\", StandardScaler(), numeric_cols)])\n",
    "\n",
    "avg_model = AvgModel(estimators=[ct, AveragingRegressor(ESTIMATORS)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create NN model\n",
    "\n",
    "ESTIMATORS = [\n",
    "    Ridge(),\n",
    "    GradientBoostingRegressor(),\n",
    "    LinearSVR(),\n",
    "    XGBRegressor(),\n",
    "    Lasso(),\n",
    "    RandomForestRegressor(n_estimators=100),\n",
    "]\n",
    "pipelines = [make_pipeline(ct, est) for est in ESTIMATORS]\n",
    "n_features = len(features.columns)\n",
    "n_teams = len(features['team'].drop_duplicates())\n",
    "n_round_types = len(features['round_type'].drop_duplicates())\n",
    "\n",
    "def create_nn_model():\n",
    "    team_input = layers.Input(shape=(1,), dtype='int32', name='team')\n",
    "    oppo_team_input = layers.Input(shape=(1,), dtype='int32', name='oppo_team')\n",
    "    round_type_input = layers.Input(shape=(1,), dtype='int32', name='round_type')\n",
    "    stats_input = layers.Input(shape=(n_features - 3,), dtype='float32', name='stats')\n",
    "\n",
    "    team_layer = layers.Embedding(n_teams * 2, 4, input_length=1)(team_input)\n",
    "    flatten_team_layer = layers.Flatten()(team_layer)\n",
    "    oppo_team_layer = layers.Embedding(n_teams * 2, 4, input_length=1)(oppo_team_input)\n",
    "    flatten_oppo_team_layer = layers.Flatten()(oppo_team_layer)\n",
    "    round_type_layer = layers.Embedding(n_round_types * 2, 4, input_length=1)(round_type_input)\n",
    "    flatten_round_layer = layers.Flatten()(round_type_layer)\n",
    "    \n",
    "    concated_layers = layers.concatenate(\n",
    "        [flatten_team_layer, flatten_oppo_team_layer, flatten_round_layer, stats_input]\n",
    "    )\n",
    "    layer_1 = layers.Dense(75, input_shape=(n_features,), activation='relu')(concated_layers)\n",
    "    dropout_1 = layers.Dropout(0.1)(layer_1)\n",
    "    layer_2 = layers.Dense(75, input_shape=(n_features,), activation='relu')(dropout_1)\n",
    "    dropout_2 = layers.Dropout(0.1)(layer_2)\n",
    "    layer_3 = layers.Dense(75, input_shape=(n_features,), activation='relu')(dropout_2)\n",
    "    dropout_3 = layers.Dropout(0.1)(layer_3)\n",
    "    output = layers.Dense(1)(dropout_3)\n",
    "\n",
    "    model = models.Model(\n",
    "        inputs=[\n",
    "            team_input,\n",
    "            oppo_team_input,\n",
    "            round_type_input,\n",
    "            stats_input\n",
    "        ],\n",
    "        outputs=output\n",
    "    )\n",
    "    model.compile(loss='mean_absolute_error', optimizer='adam', metrics=[tip_accuracy])\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "nn_ct = ColumnTransformer(\n",
    "    [(\"ordinal\", OrdinalEncoder(categories=categories), CATEGORY_COLS),\n",
    "     (\"scaling\", StandardScaler(), numeric_cols)]\n",
    ")\n",
    "\n",
    "nn_pipe = make_pipeline(\n",
    "    nn_ct,\n",
    "    InputLister(n_inputs=4),\n",
    "    KerasRegressor(build_fn=create_nn_model,\n",
    "                   epochs=20,\n",
    "                   validation_split=0.2)\n",
    ")\n",
    "\n",
    "pipelines.append(nn_pipe)\n",
    "\n",
    "avg_model = AvgModel(estimators=[AveragingRegressor(pipelines)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare current avg model to one with a NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training avg\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17950 samples, validate on 4488 samples\n",
      "Epoch 1/20\n",
      "17950/17950 [==============================] - 2s 97us/step - loss: 28.0359 - tip_accuracy: 0.6802 - val_loss: 27.1792 - val_tip_accuracy: 0.7043\n",
      "Epoch 2/20\n",
      "17950/17950 [==============================] - 1s 67us/step - loss: 26.8946 - tip_accuracy: 0.7028 - val_loss: 27.0426 - val_tip_accuracy: 0.7083\n",
      "Epoch 3/20\n",
      "17950/17950 [==============================] - 1s 74us/step - loss: 26.6917 - tip_accuracy: 0.7065 - val_loss: 26.9312 - val_tip_accuracy: 0.7054\n",
      "Epoch 4/20\n",
      "17950/17950 [==============================] - 2s 87us/step - loss: 26.5603 - tip_accuracy: 0.7097 - val_loss: 27.0471 - val_tip_accuracy: 0.7052\n",
      "Epoch 5/20\n",
      "17950/17950 [==============================] - 1s 82us/step - loss: 26.5477 - tip_accuracy: 0.7142 - val_loss: 27.0972 - val_tip_accuracy: 0.7043\n",
      "Epoch 6/20\n",
      "17950/17950 [==============================] - 1s 68us/step - loss: 26.4452 - tip_accuracy: 0.7142 - val_loss: 26.8833 - val_tip_accuracy: 0.7025\n",
      "Epoch 7/20\n",
      "17950/17950 [==============================] - 1s 69us/step - loss: 26.2978 - tip_accuracy: 0.7145 - val_loss: 26.9418 - val_tip_accuracy: 0.7030\n",
      "Epoch 8/20\n",
      "17950/17950 [==============================] - 1s 74us/step - loss: 26.2878 - tip_accuracy: 0.7170 - val_loss: 26.7905 - val_tip_accuracy: 0.7063\n",
      "Epoch 9/20\n",
      "17950/17950 [==============================] - 1s 82us/step - loss: 26.2281 - tip_accuracy: 0.7184 - val_loss: 26.7302 - val_tip_accuracy: 0.7077\n",
      "Epoch 10/20\n",
      "17950/17950 [==============================] - 2s 94us/step - loss: 26.1574 - tip_accuracy: 0.7179 - val_loss: 26.9436 - val_tip_accuracy: 0.7066\n",
      "Epoch 11/20\n",
      "17950/17950 [==============================] - 1s 75us/step - loss: 26.0732 - tip_accuracy: 0.7182 - val_loss: 26.7281 - val_tip_accuracy: 0.7092\n",
      "Epoch 12/20\n",
      "17950/17950 [==============================] - 1s 70us/step - loss: 26.0591 - tip_accuracy: 0.7211 - val_loss: 27.0279 - val_tip_accuracy: 0.7112\n",
      "Epoch 13/20\n",
      "17950/17950 [==============================] - 1s 74us/step - loss: 26.0106 - tip_accuracy: 0.7216 - val_loss: 26.8157 - val_tip_accuracy: 0.7086\n",
      "Epoch 14/20\n",
      "17950/17950 [==============================] - 1s 73us/step - loss: 25.9665 - tip_accuracy: 0.7206 - val_loss: 26.8109 - val_tip_accuracy: 0.7103\n",
      "Epoch 15/20\n",
      "17950/17950 [==============================] - 2s 89us/step - loss: 25.8948 - tip_accuracy: 0.7226 - val_loss: 26.8357 - val_tip_accuracy: 0.7106\n",
      "Epoch 16/20\n",
      "17950/17950 [==============================] - 2s 88us/step - loss: 25.8749 - tip_accuracy: 0.7202 - val_loss: 26.7863 - val_tip_accuracy: 0.7112\n",
      "Epoch 17/20\n",
      "17950/17950 [==============================] - 1s 80us/step - loss: 25.7948 - tip_accuracy: 0.7238 - val_loss: 26.8329 - val_tip_accuracy: 0.7061\n",
      "Epoch 18/20\n",
      "17950/17950 [==============================] - 2s 95us/step - loss: 25.8138 - tip_accuracy: 0.7264 - val_loss: 26.8094 - val_tip_accuracy: 0.7052\n",
      "Epoch 19/20\n",
      "17950/17950 [==============================] - 2s 93us/step - loss: 25.7196 - tip_accuracy: 0.7267 - val_loss: 26.8806 - val_tip_accuracy: 0.7074\n",
      "Epoch 20/20\n",
      "17950/17950 [==============================] - 2s 88us/step - loss: 25.7362 - tip_accuracy: 0.7258 - val_loss: 26.8962 - val_tip_accuracy: 0.7106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3590 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 2s 116us/step - loss: 28.3843 - tip_accuracy: 0.6701 - val_loss: 27.0590 - val_tip_accuracy: 0.7111\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 1s 71us/step - loss: 27.0392 - tip_accuracy: 0.6978 - val_loss: 27.0746 - val_tip_accuracy: 0.7058\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 1s 79us/step - loss: 26.9189 - tip_accuracy: 0.7033 - val_loss: 27.1638 - val_tip_accuracy: 0.7067\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 1s 76us/step - loss: 26.7628 - tip_accuracy: 0.7064 - val_loss: 27.1737 - val_tip_accuracy: 0.7022\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 1s 78us/step - loss: 26.6408 - tip_accuracy: 0.7097 - val_loss: 27.0236 - val_tip_accuracy: 0.7109\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 1s 81us/step - loss: 26.5834 - tip_accuracy: 0.7097 - val_loss: 26.9834 - val_tip_accuracy: 0.7086\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 1s 92us/step - loss: 26.4945 - tip_accuracy: 0.7093 - val_loss: 26.8838 - val_tip_accuracy: 0.7117\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 1s 79us/step - loss: 26.3512 - tip_accuracy: 0.7117 - val_loss: 27.0147 - val_tip_accuracy: 0.7089\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 1s 74us/step - loss: 26.3043 - tip_accuracy: 0.7130 - val_loss: 26.9036 - val_tip_accuracy: 0.7056\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 1s 81us/step - loss: 26.2360 - tip_accuracy: 0.7158 - val_loss: 26.9343 - val_tip_accuracy: 0.7111\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 1s 89us/step - loss: 26.1546 - tip_accuracy: 0.7178 - val_loss: 27.0964 - val_tip_accuracy: 0.7072\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 1s 81us/step - loss: 26.1716 - tip_accuracy: 0.7205 - val_loss: 27.0395 - val_tip_accuracy: 0.7042\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 1s 81us/step - loss: 26.0920 - tip_accuracy: 0.7192 - val_loss: 27.2774 - val_tip_accuracy: 0.7045\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 1s 79us/step - loss: 25.9948 - tip_accuracy: 0.7201 - val_loss: 26.8481 - val_tip_accuracy: 0.7078\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 1s 76us/step - loss: 26.0451 - tip_accuracy: 0.7204 - val_loss: 27.0055 - val_tip_accuracy: 0.7114\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 1s 83us/step - loss: 25.9134 - tip_accuracy: 0.7241 - val_loss: 27.0253 - val_tip_accuracy: 0.7025\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 1s 80us/step - loss: 25.8918 - tip_accuracy: 0.7240 - val_loss: 26.9739 - val_tip_accuracy: 0.7070\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 1s 79us/step - loss: 25.8556 - tip_accuracy: 0.7237 - val_loss: 27.0361 - val_tip_accuracy: 0.7025\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 1s 76us/step - loss: 25.7066 - tip_accuracy: 0.7253 - val_loss: 26.9038 - val_tip_accuracy: 0.7061\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 1s 76us/step - loss: 25.6989 - tip_accuracy: 0.7253 - val_loss: 27.1574 - val_tip_accuracy: 0.7014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3590 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 2s 117us/step - loss: 28.2149 - tip_accuracy: 0.6815 - val_loss: 27.4033 - val_tip_accuracy: 0.7070\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 1s 82us/step - loss: 26.9835 - tip_accuracy: 0.7042 - val_loss: 27.0718 - val_tip_accuracy: 0.7064\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 1s 78us/step - loss: 26.7375 - tip_accuracy: 0.7088 - val_loss: 26.8968 - val_tip_accuracy: 0.7061\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 1s 87us/step - loss: 26.6259 - tip_accuracy: 0.7086 - val_loss: 27.0880 - val_tip_accuracy: 0.7025\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 1s 89us/step - loss: 26.5142 - tip_accuracy: 0.7125 - val_loss: 26.8899 - val_tip_accuracy: 0.7072\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 1s 80us/step - loss: 26.4313 - tip_accuracy: 0.7121 - val_loss: 26.9357 - val_tip_accuracy: 0.7067\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 1s 80us/step - loss: 26.2536 - tip_accuracy: 0.7138 - val_loss: 26.8507 - val_tip_accuracy: 0.7067\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 1s 76us/step - loss: 26.2201 - tip_accuracy: 0.7134 - val_loss: 26.8985 - val_tip_accuracy: 0.7123\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 1s 75us/step - loss: 26.1594 - tip_accuracy: 0.7129 - val_loss: 27.0404 - val_tip_accuracy: 0.6992\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 1s 78us/step - loss: 26.1692 - tip_accuracy: 0.7151 - val_loss: 26.9669 - val_tip_accuracy: 0.7084\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 1s 73us/step - loss: 26.0577 - tip_accuracy: 0.7189 - val_loss: 26.8898 - val_tip_accuracy: 0.7084\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 1s 76us/step - loss: 26.0483 - tip_accuracy: 0.7190 - val_loss: 26.8443 - val_tip_accuracy: 0.7084\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 1s 74us/step - loss: 25.9610 - tip_accuracy: 0.7187 - val_loss: 26.7183 - val_tip_accuracy: 0.7103\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 1s 75us/step - loss: 25.9142 - tip_accuracy: 0.7206 - val_loss: 27.0526 - val_tip_accuracy: 0.7072\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 1s 98us/step - loss: 25.8557 - tip_accuracy: 0.7224 - val_loss: 26.9584 - val_tip_accuracy: 0.7072\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 1s 78us/step - loss: 25.8569 - tip_accuracy: 0.7205 - val_loss: 26.9000 - val_tip_accuracy: 0.7070\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 1s 75us/step - loss: 25.7601 - tip_accuracy: 0.7235 - val_loss: 26.8093 - val_tip_accuracy: 0.7089\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 1s 76us/step - loss: 25.7603 - tip_accuracy: 0.7215 - val_loss: 27.1503 - val_tip_accuracy: 0.7084\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 1s 76us/step - loss: 25.7148 - tip_accuracy: 0.7224 - val_loss: 26.7977 - val_tip_accuracy: 0.7081\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 1s 80us/step - loss: 25.6151 - tip_accuracy: 0.7256 - val_loss: 27.1816 - val_tip_accuracy: 0.7123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3590 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 2s 116us/step - loss: 28.3799 - tip_accuracy: 0.6767 - val_loss: 27.4462 - val_tip_accuracy: 0.7089\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 1s 75us/step - loss: 27.1827 - tip_accuracy: 0.7030 - val_loss: 27.0196 - val_tip_accuracy: 0.7061\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 1s 74us/step - loss: 26.8841 - tip_accuracy: 0.7047 - val_loss: 26.9785 - val_tip_accuracy: 0.7031\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 1s 82us/step - loss: 26.8016 - tip_accuracy: 0.7075 - val_loss: 27.2369 - val_tip_accuracy: 0.6989\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 1s 76us/step - loss: 26.6768 - tip_accuracy: 0.7077 - val_loss: 26.8708 - val_tip_accuracy: 0.7075\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 1s 82us/step - loss: 26.6464 - tip_accuracy: 0.7121 - val_loss: 26.8570 - val_tip_accuracy: 0.7061\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 1s 77us/step - loss: 26.5030 - tip_accuracy: 0.7143 - val_loss: 26.9325 - val_tip_accuracy: 0.7078\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 1s 77us/step - loss: 26.4358 - tip_accuracy: 0.7144 - val_loss: 26.8106 - val_tip_accuracy: 0.7061\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 1s 76us/step - loss: 26.3611 - tip_accuracy: 0.7156 - val_loss: 26.7579 - val_tip_accuracy: 0.7089\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 1s 77us/step - loss: 26.3337 - tip_accuracy: 0.7187 - val_loss: 26.7760 - val_tip_accuracy: 0.7061\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 1s 78us/step - loss: 26.2605 - tip_accuracy: 0.7169 - val_loss: 26.8474 - val_tip_accuracy: 0.7058\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 1s 72us/step - loss: 26.2158 - tip_accuracy: 0.7189 - val_loss: 27.1136 - val_tip_accuracy: 0.6986\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 1s 82us/step - loss: 26.1899 - tip_accuracy: 0.7192 - val_loss: 26.8088 - val_tip_accuracy: 0.7006\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 1s 74us/step - loss: 26.1335 - tip_accuracy: 0.7212 - val_loss: 26.7386 - val_tip_accuracy: 0.7028\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 1s 78us/step - loss: 25.9941 - tip_accuracy: 0.7213 - val_loss: 26.8390 - val_tip_accuracy: 0.7022\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 1s 86us/step - loss: 25.9468 - tip_accuracy: 0.7224 - val_loss: 26.9024 - val_tip_accuracy: 0.7045\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 1s 80us/step - loss: 25.9273 - tip_accuracy: 0.7224 - val_loss: 26.9137 - val_tip_accuracy: 0.7017\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 1s 74us/step - loss: 25.8707 - tip_accuracy: 0.7233 - val_loss: 27.0420 - val_tip_accuracy: 0.7031\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 1s 76us/step - loss: 25.8614 - tip_accuracy: 0.7244 - val_loss: 27.0260 - val_tip_accuracy: 0.7047\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 1s 83us/step - loss: 25.8029 - tip_accuracy: 0.7267 - val_loss: 26.8187 - val_tip_accuracy: 0.7019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3591 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 2s 127us/step - loss: 28.1496 - tip_accuracy: 0.6761 - val_loss: 27.3186 - val_tip_accuracy: 0.7054\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 1s 77us/step - loss: 26.8945 - tip_accuracy: 0.6995 - val_loss: 27.0908 - val_tip_accuracy: 0.7132\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 1s 86us/step - loss: 26.7403 - tip_accuracy: 0.7048 - val_loss: 26.9343 - val_tip_accuracy: 0.7073\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 1s 84us/step - loss: 26.5912 - tip_accuracy: 0.7058 - val_loss: 26.9309 - val_tip_accuracy: 0.7054\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 1s 80us/step - loss: 26.4319 - tip_accuracy: 0.7095 - val_loss: 26.9119 - val_tip_accuracy: 0.7098\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 1s 90us/step - loss: 26.3696 - tip_accuracy: 0.7118 - val_loss: 26.8771 - val_tip_accuracy: 0.7051\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 1s 86us/step - loss: 26.2535 - tip_accuracy: 0.7127 - val_loss: 26.8290 - val_tip_accuracy: 0.7079\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 1s 80us/step - loss: 26.1635 - tip_accuracy: 0.7120 - val_loss: 26.6437 - val_tip_accuracy: 0.7101\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 1s 83us/step - loss: 26.1249 - tip_accuracy: 0.7155 - val_loss: 26.8018 - val_tip_accuracy: 0.7082\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 1s 77us/step - loss: 26.0818 - tip_accuracy: 0.7157 - val_loss: 26.7270 - val_tip_accuracy: 0.7079\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 1s 78us/step - loss: 26.0175 - tip_accuracy: 0.7174 - val_loss: 26.6738 - val_tip_accuracy: 0.7070\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 1s 81us/step - loss: 25.9498 - tip_accuracy: 0.7205 - val_loss: 26.6740 - val_tip_accuracy: 0.7132\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 1s 79us/step - loss: 25.8955 - tip_accuracy: 0.7194 - val_loss: 26.7337 - val_tip_accuracy: 0.7076\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 1s 85us/step - loss: 25.7784 - tip_accuracy: 0.7192 - val_loss: 26.8744 - val_tip_accuracy: 0.7098\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 1s 85us/step - loss: 25.7299 - tip_accuracy: 0.7244 - val_loss: 26.7596 - val_tip_accuracy: 0.7057\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 1s 92us/step - loss: 25.7861 - tip_accuracy: 0.7226 - val_loss: 26.8195 - val_tip_accuracy: 0.7137\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 1s 85us/step - loss: 25.6229 - tip_accuracy: 0.7268 - val_loss: 26.7903 - val_tip_accuracy: 0.7098\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 1s 91us/step - loss: 25.6552 - tip_accuracy: 0.7240 - val_loss: 26.8065 - val_tip_accuracy: 0.7084\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 1s 78us/step - loss: 25.5248 - tip_accuracy: 0.7269 - val_loss: 26.7338 - val_tip_accuracy: 0.7096\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 1s 77us/step - loss: 25.5484 - tip_accuracy: 0.7260 - val_loss: 26.8962 - val_tip_accuracy: 0.7104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3591 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 2s 130us/step - loss: 28.1296 - tip_accuracy: 0.6853 - val_loss: 27.5929 - val_tip_accuracy: 0.6992\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 1s 82us/step - loss: 26.8550 - tip_accuracy: 0.7034 - val_loss: 27.2092 - val_tip_accuracy: 0.6995\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 1s 81us/step - loss: 26.7007 - tip_accuracy: 0.7073 - val_loss: 27.0341 - val_tip_accuracy: 0.7029\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 1s 79us/step - loss: 26.5523 - tip_accuracy: 0.7087 - val_loss: 27.0067 - val_tip_accuracy: 0.7015\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 1s 81us/step - loss: 26.4479 - tip_accuracy: 0.7115 - val_loss: 26.9267 - val_tip_accuracy: 0.7073\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 1s 77us/step - loss: 26.3124 - tip_accuracy: 0.7155 - val_loss: 26.8903 - val_tip_accuracy: 0.7084\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 1s 73us/step - loss: 26.2627 - tip_accuracy: 0.7170 - val_loss: 26.9785 - val_tip_accuracy: 0.7087\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 1s 77us/step - loss: 26.2045 - tip_accuracy: 0.7158 - val_loss: 26.8622 - val_tip_accuracy: 0.7096\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 1s 78us/step - loss: 26.1056 - tip_accuracy: 0.7211 - val_loss: 26.9849 - val_tip_accuracy: 0.7068\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 1s 79us/step - loss: 26.0311 - tip_accuracy: 0.7185 - val_loss: 27.0696 - val_tip_accuracy: 0.7082\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 1s 85us/step - loss: 25.9411 - tip_accuracy: 0.7217 - val_loss: 26.9225 - val_tip_accuracy: 0.7090\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 1s 79us/step - loss: 25.8554 - tip_accuracy: 0.7228 - val_loss: 27.0548 - val_tip_accuracy: 0.7031\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 1s 81us/step - loss: 25.8810 - tip_accuracy: 0.7228 - val_loss: 26.9312 - val_tip_accuracy: 0.7029\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 1s 80us/step - loss: 25.7970 - tip_accuracy: 0.7232 - val_loss: 27.0894 - val_tip_accuracy: 0.7076\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 1s 87us/step - loss: 25.7293 - tip_accuracy: 0.7281 - val_loss: 27.0757 - val_tip_accuracy: 0.7132\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 1s 84us/step - loss: 25.7670 - tip_accuracy: 0.7242 - val_loss: 26.9681 - val_tip_accuracy: 0.7026\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 1s 81us/step - loss: 25.6752 - tip_accuracy: 0.7243 - val_loss: 26.9507 - val_tip_accuracy: 0.7031\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 1s 80us/step - loss: 25.5910 - tip_accuracy: 0.7295 - val_loss: 27.1812 - val_tip_accuracy: 0.7034\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 1s 77us/step - loss: 25.5355 - tip_accuracy: 0.7301 - val_loss: 27.0231 - val_tip_accuracy: 0.7015\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 1s 86us/step - loss: 25.5080 - tip_accuracy: 0.7313 - val_loss: 27.0839 - val_tip_accuracy: 0.7009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3590 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 2s 136us/step - loss: 28.3352 - tip_accuracy: 0.6782 - val_loss: 27.3493 - val_tip_accuracy: 0.7011\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 1s 79us/step - loss: 27.0690 - tip_accuracy: 0.6994 - val_loss: 27.0368 - val_tip_accuracy: 0.7120\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 1s 95us/step - loss: 26.8606 - tip_accuracy: 0.7030 - val_loss: 27.0672 - val_tip_accuracy: 0.7061\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 1s 83us/step - loss: 26.7365 - tip_accuracy: 0.7053 - val_loss: 26.9121 - val_tip_accuracy: 0.7117\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 1s 83us/step - loss: 26.6094 - tip_accuracy: 0.7058 - val_loss: 27.0532 - val_tip_accuracy: 0.7086\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 1s 98us/step - loss: 26.5636 - tip_accuracy: 0.7083 - val_loss: 26.8982 - val_tip_accuracy: 0.7086\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 1s 82us/step - loss: 26.4695 - tip_accuracy: 0.7111 - val_loss: 27.0328 - val_tip_accuracy: 0.7092\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 1s 80us/step - loss: 26.3753 - tip_accuracy: 0.7132 - val_loss: 26.9267 - val_tip_accuracy: 0.7111\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 1s 79us/step - loss: 26.2666 - tip_accuracy: 0.7133 - val_loss: 27.0017 - val_tip_accuracy: 0.7061\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 1s 83us/step - loss: 26.1933 - tip_accuracy: 0.7179 - val_loss: 26.9177 - val_tip_accuracy: 0.7100\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 1s 79us/step - loss: 26.1010 - tip_accuracy: 0.7192 - val_loss: 26.8999 - val_tip_accuracy: 0.7111\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 1s 83us/step - loss: 26.1343 - tip_accuracy: 0.7180 - val_loss: 26.7810 - val_tip_accuracy: 0.7097\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 1s 81us/step - loss: 26.0302 - tip_accuracy: 0.7200 - val_loss: 26.9354 - val_tip_accuracy: 0.7086\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 1s 78us/step - loss: 25.9849 - tip_accuracy: 0.7219 - val_loss: 26.9781 - val_tip_accuracy: 0.7084\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 1s 84us/step - loss: 25.9094 - tip_accuracy: 0.7216 - val_loss: 26.8731 - val_tip_accuracy: 0.7109\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 1s 80us/step - loss: 25.8702 - tip_accuracy: 0.7253 - val_loss: 26.8844 - val_tip_accuracy: 0.7092\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 1s 83us/step - loss: 25.8361 - tip_accuracy: 0.7239 - val_loss: 26.8742 - val_tip_accuracy: 0.7075\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 1s 81us/step - loss: 25.8136 - tip_accuracy: 0.7261 - val_loss: 26.8468 - val_tip_accuracy: 0.7067\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 1s 81us/step - loss: 25.7499 - tip_accuracy: 0.7267 - val_loss: 26.8905 - val_tip_accuracy: 0.7070\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 1s 85us/step - loss: 25.7870 - tip_accuracy: 0.7241 - val_loss: 26.8544 - val_tip_accuracy: 0.7075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3590 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 2s 149us/step - loss: 28.1677 - tip_accuracy: 0.6786 - val_loss: 27.1507 - val_tip_accuracy: 0.7109\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 1s 95us/step - loss: 26.9013 - tip_accuracy: 0.7041 - val_loss: 26.9627 - val_tip_accuracy: 0.7084\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 1s 102us/step - loss: 26.7250 - tip_accuracy: 0.7060 - val_loss: 26.8437 - val_tip_accuracy: 0.7114\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 1s 99us/step - loss: 26.6355 - tip_accuracy: 0.7101 - val_loss: 26.9966 - val_tip_accuracy: 0.7081\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 1s 90us/step - loss: 26.5061 - tip_accuracy: 0.7086 - val_loss: 26.9845 - val_tip_accuracy: 0.7047\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 1s 86us/step - loss: 26.4392 - tip_accuracy: 0.7107 - val_loss: 26.9835 - val_tip_accuracy: 0.7064\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 1s 87us/step - loss: 26.3119 - tip_accuracy: 0.7111 - val_loss: 26.8546 - val_tip_accuracy: 0.7053\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 1s 80us/step - loss: 26.2436 - tip_accuracy: 0.7182 - val_loss: 26.7915 - val_tip_accuracy: 0.7081\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 1s 89us/step - loss: 26.2792 - tip_accuracy: 0.7132 - val_loss: 26.7432 - val_tip_accuracy: 0.7042\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 1s 81us/step - loss: 26.1984 - tip_accuracy: 0.7155 - val_loss: 27.0022 - val_tip_accuracy: 0.7086\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 1s 83us/step - loss: 26.1198 - tip_accuracy: 0.7145 - val_loss: 26.8852 - val_tip_accuracy: 0.7084\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 1s 83us/step - loss: 26.0201 - tip_accuracy: 0.7180 - val_loss: 26.9187 - val_tip_accuracy: 0.7078\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 1s 83us/step - loss: 25.9889 - tip_accuracy: 0.7175 - val_loss: 26.8272 - val_tip_accuracy: 0.7070\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 1s 85us/step - loss: 25.9908 - tip_accuracy: 0.7182 - val_loss: 26.7470 - val_tip_accuracy: 0.7075\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 1s 82us/step - loss: 25.9284 - tip_accuracy: 0.7200 - val_loss: 26.8428 - val_tip_accuracy: 0.7086\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 1s 82us/step - loss: 25.8875 - tip_accuracy: 0.7219 - val_loss: 26.9600 - val_tip_accuracy: 0.7050\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 1s 76us/step - loss: 25.8102 - tip_accuracy: 0.7214 - val_loss: 26.7814 - val_tip_accuracy: 0.7136\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 1s 88us/step - loss: 25.7412 - tip_accuracy: 0.7234 - val_loss: 26.8768 - val_tip_accuracy: 0.7111\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 1s 87us/step - loss: 25.7503 - tip_accuracy: 0.7283 - val_loss: 26.9314 - val_tip_accuracy: 0.7111\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 1s 84us/step - loss: 25.6417 - tip_accuracy: 0.7236 - val_loss: 26.7920 - val_tip_accuracy: 0.7084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3590 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 2s 173us/step - loss: 28.3981 - tip_accuracy: 0.6804 - val_loss: 27.1335 - val_tip_accuracy: 0.7070\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 1s 91us/step - loss: 27.0865 - tip_accuracy: 0.7009 - val_loss: 27.2248 - val_tip_accuracy: 0.7045\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 1s 92us/step - loss: 26.9210 - tip_accuracy: 0.7069 - val_loss: 26.8989 - val_tip_accuracy: 0.7011\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 1s 89us/step - loss: 26.7546 - tip_accuracy: 0.7088 - val_loss: 26.8346 - val_tip_accuracy: 0.7056\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 1s 87us/step - loss: 26.6319 - tip_accuracy: 0.7124 - val_loss: 26.9422 - val_tip_accuracy: 0.7086\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 1s 91us/step - loss: 26.5236 - tip_accuracy: 0.7130 - val_loss: 26.9395 - val_tip_accuracy: 0.7050\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 1s 83us/step - loss: 26.4952 - tip_accuracy: 0.7134 - val_loss: 26.8432 - val_tip_accuracy: 0.7081\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 1s 81us/step - loss: 26.4186 - tip_accuracy: 0.7149 - val_loss: 26.8969 - val_tip_accuracy: 0.7064\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 1s 87us/step - loss: 26.3368 - tip_accuracy: 0.7168 - val_loss: 26.9867 - val_tip_accuracy: 0.7114\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 1s 85us/step - loss: 26.2111 - tip_accuracy: 0.7197 - val_loss: 26.8413 - val_tip_accuracy: 0.7064\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 1s 86us/step - loss: 26.2005 - tip_accuracy: 0.7215 - val_loss: 26.7983 - val_tip_accuracy: 0.7086\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 1s 86us/step - loss: 26.1358 - tip_accuracy: 0.7231 - val_loss: 26.8249 - val_tip_accuracy: 0.7067\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 1s 85us/step - loss: 26.1105 - tip_accuracy: 0.7224 - val_loss: 26.7662 - val_tip_accuracy: 0.7109\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 1s 88us/step - loss: 26.0717 - tip_accuracy: 0.7203 - val_loss: 26.7790 - val_tip_accuracy: 0.7050\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 1s 85us/step - loss: 26.0204 - tip_accuracy: 0.7221 - val_loss: 26.8333 - val_tip_accuracy: 0.7125\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 1s 86us/step - loss: 25.9491 - tip_accuracy: 0.7248 - val_loss: 26.7893 - val_tip_accuracy: 0.7109\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 1s 86us/step - loss: 25.9322 - tip_accuracy: 0.7231 - val_loss: 26.7428 - val_tip_accuracy: 0.7061\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 1s 83us/step - loss: 25.8751 - tip_accuracy: 0.7240 - val_loss: 26.8426 - val_tip_accuracy: 0.7114\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 1s 88us/step - loss: 25.8091 - tip_accuracy: 0.7256 - val_loss: 26.8219 - val_tip_accuracy: 0.7078\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 1s 85us/step - loss: 25.7649 - tip_accuracy: 0.7249 - val_loss: 27.0672 - val_tip_accuracy: 0.7053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3591 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 3s 187us/step - loss: 28.3803 - tip_accuracy: 0.6727 - val_loss: 27.1806 - val_tip_accuracy: 0.7084\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 1s 101us/step - loss: 26.8747 - tip_accuracy: 0.7025 - val_loss: 27.0460 - val_tip_accuracy: 0.7087\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 1s 102us/step - loss: 26.6679 - tip_accuracy: 0.7063 - val_loss: 26.9361 - val_tip_accuracy: 0.7062\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 2s 126us/step - loss: 26.6388 - tip_accuracy: 0.7074 - val_loss: 26.8806 - val_tip_accuracy: 0.7076\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 1s 101us/step - loss: 26.4841 - tip_accuracy: 0.7091 - val_loss: 26.9213 - val_tip_accuracy: 0.7079\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 2s 107us/step - loss: 26.3387 - tip_accuracy: 0.7111 - val_loss: 26.8160 - val_tip_accuracy: 0.7079\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 1s 104us/step - loss: 26.3074 - tip_accuracy: 0.7128 - val_loss: 26.8896 - val_tip_accuracy: 0.7090\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 1s 103us/step - loss: 26.2152 - tip_accuracy: 0.7120 - val_loss: 26.8402 - val_tip_accuracy: 0.7140\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 2s 106us/step - loss: 26.0935 - tip_accuracy: 0.7157 - val_loss: 26.8360 - val_tip_accuracy: 0.7098\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 2s 110us/step - loss: 26.1012 - tip_accuracy: 0.7187 - val_loss: 26.8222 - val_tip_accuracy: 0.7093\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 2s 106us/step - loss: 26.0504 - tip_accuracy: 0.7215 - val_loss: 26.7482 - val_tip_accuracy: 0.7087\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 2s 138us/step - loss: 25.9502 - tip_accuracy: 0.7210 - val_loss: 26.8205 - val_tip_accuracy: 0.7135\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 2s 152us/step - loss: 25.9612 - tip_accuracy: 0.7228 - val_loss: 26.8368 - val_tip_accuracy: 0.7107\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 2s 167us/step - loss: 25.8786 - tip_accuracy: 0.7203 - val_loss: 26.8113 - val_tip_accuracy: 0.7098\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 2s 162us/step - loss: 25.7608 - tip_accuracy: 0.7233 - val_loss: 26.7978 - val_tip_accuracy: 0.7154\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 2s 159us/step - loss: 25.7621 - tip_accuracy: 0.7260 - val_loss: 26.8250 - val_tip_accuracy: 0.7084\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 2s 156us/step - loss: 25.6154 - tip_accuracy: 0.7278 - val_loss: 26.8496 - val_tip_accuracy: 0.7121\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 2s 106us/step - loss: 25.5974 - tip_accuracy: 0.7273 - val_loss: 26.8997 - val_tip_accuracy: 0.7104\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 2s 108us/step - loss: 25.5709 - tip_accuracy: 0.7286 - val_loss: 26.8456 - val_tip_accuracy: 0.7104\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 2s 107us/step - loss: 25.5989 - tip_accuracy: 0.7285 - val_loss: 26.9232 - val_tip_accuracy: 0.7079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3591 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 3s 176us/step - loss: 28.2658 - tip_accuracy: 0.6756 - val_loss: 27.1311 - val_tip_accuracy: 0.6998\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 1s 90us/step - loss: 26.8402 - tip_accuracy: 0.7016 - val_loss: 27.1536 - val_tip_accuracy: 0.7012\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 1s 102us/step - loss: 26.6595 - tip_accuracy: 0.7057 - val_loss: 26.9490 - val_tip_accuracy: 0.7082\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 1s 93us/step - loss: 26.5611 - tip_accuracy: 0.7067 - val_loss: 26.9563 - val_tip_accuracy: 0.7076\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 1s 97us/step - loss: 26.4429 - tip_accuracy: 0.7123 - val_loss: 26.9703 - val_tip_accuracy: 0.7006\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 1s 99us/step - loss: 26.3812 - tip_accuracy: 0.7115 - val_loss: 27.1235 - val_tip_accuracy: 0.7009\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 1s 97us/step - loss: 26.2828 - tip_accuracy: 0.7126 - val_loss: 26.9707 - val_tip_accuracy: 0.7087\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 1s 90us/step - loss: 26.1838 - tip_accuracy: 0.7173 - val_loss: 26.9408 - val_tip_accuracy: 0.7001\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 1s 90us/step - loss: 26.1343 - tip_accuracy: 0.7164 - val_loss: 26.8526 - val_tip_accuracy: 0.7104\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 1s 96us/step - loss: 26.0821 - tip_accuracy: 0.7223 - val_loss: 26.9837 - val_tip_accuracy: 0.7062\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 1s 93us/step - loss: 25.9779 - tip_accuracy: 0.7192 - val_loss: 26.9701 - val_tip_accuracy: 0.7079\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 1s 95us/step - loss: 25.9343 - tip_accuracy: 0.7219 - val_loss: 27.1081 - val_tip_accuracy: 0.6970\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 1s 91us/step - loss: 25.8661 - tip_accuracy: 0.7249 - val_loss: 27.1799 - val_tip_accuracy: 0.7012\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 1s 89us/step - loss: 25.8262 - tip_accuracy: 0.7249 - val_loss: 27.3695 - val_tip_accuracy: 0.7123\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 1s 89us/step - loss: 25.7985 - tip_accuracy: 0.7257 - val_loss: 27.3073 - val_tip_accuracy: 0.7129\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 1s 94us/step - loss: 25.7309 - tip_accuracy: 0.7264 - val_loss: 26.9885 - val_tip_accuracy: 0.7109\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 1s 91us/step - loss: 25.7032 - tip_accuracy: 0.7281 - val_loss: 27.0923 - val_tip_accuracy: 0.7065\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 1s 98us/step - loss: 25.6912 - tip_accuracy: 0.7289 - val_loss: 27.0394 - val_tip_accuracy: 0.7059\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 1s 94us/step - loss: 25.6178 - tip_accuracy: 0.7284 - val_loss: 26.9051 - val_tip_accuracy: 0.7068\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 1s 100us/step - loss: 25.5484 - tip_accuracy: 0.7276 - val_loss: 27.1101 - val_tip_accuracy: 0.7084\n",
      "avg done\n",
      "Training avg_nn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 17950 samples, validate on 4488 samples\n",
      "Epoch 1/20\n",
      "17950/17950 [==============================] - 3s 157us/step - loss: 28.1740 - tip_accuracy: 0.6790 - val_loss: 27.2009 - val_tip_accuracy: 0.7023\n",
      "Epoch 2/20\n",
      "17950/17950 [==============================] - 2s 93us/step - loss: 26.8772 - tip_accuracy: 0.7024 - val_loss: 27.0945 - val_tip_accuracy: 0.7061\n",
      "Epoch 3/20\n",
      "17950/17950 [==============================] - 2s 91us/step - loss: 26.7677 - tip_accuracy: 0.7060 - val_loss: 27.2252 - val_tip_accuracy: 0.7074\n",
      "Epoch 4/20\n",
      "17950/17950 [==============================] - 2s 119us/step - loss: 26.5825 - tip_accuracy: 0.7111 - val_loss: 27.1388 - val_tip_accuracy: 0.7023\n",
      "Epoch 5/20\n",
      "17950/17950 [==============================] - 2s 93us/step - loss: 26.5323 - tip_accuracy: 0.7115 - val_loss: 26.9391 - val_tip_accuracy: 0.7061\n",
      "Epoch 6/20\n",
      "17950/17950 [==============================] - 2s 88us/step - loss: 26.4000 - tip_accuracy: 0.7140 - val_loss: 27.0856 - val_tip_accuracy: 0.7061\n",
      "Epoch 7/20\n",
      "17950/17950 [==============================] - 2s 95us/step - loss: 26.3473 - tip_accuracy: 0.7135 - val_loss: 26.9349 - val_tip_accuracy: 0.7068\n",
      "Epoch 8/20\n",
      "17950/17950 [==============================] - 2s 92us/step - loss: 26.3197 - tip_accuracy: 0.7123 - val_loss: 27.0408 - val_tip_accuracy: 0.7016\n",
      "Epoch 9/20\n",
      "17950/17950 [==============================] - 2s 88us/step - loss: 26.2289 - tip_accuracy: 0.7161 - val_loss: 26.8428 - val_tip_accuracy: 0.7045\n",
      "Epoch 10/20\n",
      "17950/17950 [==============================] - 2s 88us/step - loss: 26.1673 - tip_accuracy: 0.7182 - val_loss: 26.7603 - val_tip_accuracy: 0.7074\n",
      "Epoch 11/20\n",
      "17950/17950 [==============================] - 2s 86us/step - loss: 26.1579 - tip_accuracy: 0.7185 - val_loss: 26.7305 - val_tip_accuracy: 0.7074\n",
      "Epoch 12/20\n",
      "17950/17950 [==============================] - 2s 91us/step - loss: 26.1026 - tip_accuracy: 0.7197 - val_loss: 26.7832 - val_tip_accuracy: 0.7054\n",
      "Epoch 13/20\n",
      "17950/17950 [==============================] - 2s 87us/step - loss: 26.0127 - tip_accuracy: 0.7196 - val_loss: 26.7691 - val_tip_accuracy: 0.7070\n",
      "Epoch 14/20\n",
      "17950/17950 [==============================] - 2s 88us/step - loss: 25.9966 - tip_accuracy: 0.7217 - val_loss: 26.7922 - val_tip_accuracy: 0.7083\n",
      "Epoch 15/20\n",
      "17950/17950 [==============================] - 2s 90us/step - loss: 25.9751 - tip_accuracy: 0.7217 - val_loss: 26.8474 - val_tip_accuracy: 0.7052\n",
      "Epoch 16/20\n",
      "17950/17950 [==============================] - 2s 98us/step - loss: 25.8988 - tip_accuracy: 0.7232 - val_loss: 26.7617 - val_tip_accuracy: 0.7072\n",
      "Epoch 17/20\n",
      "17950/17950 [==============================] - 2s 89us/step - loss: 25.8146 - tip_accuracy: 0.7231 - val_loss: 26.7679 - val_tip_accuracy: 0.7021\n",
      "Epoch 18/20\n",
      "17950/17950 [==============================] - 2s 88us/step - loss: 25.7943 - tip_accuracy: 0.7248 - val_loss: 26.7546 - val_tip_accuracy: 0.7079\n",
      "Epoch 19/20\n",
      "17950/17950 [==============================] - 2s 95us/step - loss: 25.7026 - tip_accuracy: 0.7245 - val_loss: 26.8795 - val_tip_accuracy: 0.7077\n",
      "Epoch 20/20\n",
      "17950/17950 [==============================] - 2s 92us/step - loss: 25.6446 - tip_accuracy: 0.7274 - val_loss: 26.8792 - val_tip_accuracy: 0.7034\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3590 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 3s 202us/step - loss: 28.3291 - tip_accuracy: 0.6768 - val_loss: 27.2095 - val_tip_accuracy: 0.7089\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 1s 94us/step - loss: 27.0457 - tip_accuracy: 0.7011 - val_loss: 27.0158 - val_tip_accuracy: 0.7053\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 1s 94us/step - loss: 26.8406 - tip_accuracy: 0.7033 - val_loss: 26.8959 - val_tip_accuracy: 0.7070\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 2s 109us/step - loss: 26.7579 - tip_accuracy: 0.7055 - val_loss: 26.8174 - val_tip_accuracy: 0.7117\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 2s 111us/step - loss: 26.6405 - tip_accuracy: 0.7099 - val_loss: 26.9305 - val_tip_accuracy: 0.7058\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 1s 95us/step - loss: 26.5700 - tip_accuracy: 0.7118 - val_loss: 26.9350 - val_tip_accuracy: 0.7145\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 2s 114us/step - loss: 26.4456 - tip_accuracy: 0.7139 - val_loss: 26.8627 - val_tip_accuracy: 0.7103\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 1s 97us/step - loss: 26.4148 - tip_accuracy: 0.7141 - val_loss: 26.8655 - val_tip_accuracy: 0.7028\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 1s 93us/step - loss: 26.3270 - tip_accuracy: 0.7144 - val_loss: 26.8609 - val_tip_accuracy: 0.7081\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 2s 117us/step - loss: 26.2517 - tip_accuracy: 0.7171 - val_loss: 26.8511 - val_tip_accuracy: 0.7111\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 1s 97us/step - loss: 26.2360 - tip_accuracy: 0.7161 - val_loss: 26.8289 - val_tip_accuracy: 0.7100\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 1s 97us/step - loss: 26.1580 - tip_accuracy: 0.7199 - val_loss: 26.8236 - val_tip_accuracy: 0.7053\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 1s 104us/step - loss: 26.0610 - tip_accuracy: 0.7202 - val_loss: 26.8708 - val_tip_accuracy: 0.7134\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 1s 93us/step - loss: 26.0878 - tip_accuracy: 0.7203 - val_loss: 26.9177 - val_tip_accuracy: 0.7103\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 1s 96us/step - loss: 26.0213 - tip_accuracy: 0.7221 - val_loss: 27.1638 - val_tip_accuracy: 0.7092\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 1s 97us/step - loss: 25.9444 - tip_accuracy: 0.7208 - val_loss: 26.9091 - val_tip_accuracy: 0.7058\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 2s 111us/step - loss: 25.8771 - tip_accuracy: 0.7235 - val_loss: 27.2035 - val_tip_accuracy: 0.7070\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 2s 111us/step - loss: 25.8220 - tip_accuracy: 0.7260 - val_loss: 27.0682 - val_tip_accuracy: 0.7092\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 2s 114us/step - loss: 25.8445 - tip_accuracy: 0.7275 - val_loss: 26.9373 - val_tip_accuracy: 0.7070\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 1s 96us/step - loss: 25.6963 - tip_accuracy: 0.7244 - val_loss: 26.9665 - val_tip_accuracy: 0.7061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3590 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 3s 188us/step - loss: 28.4123 - tip_accuracy: 0.6664 - val_loss: 27.0589 - val_tip_accuracy: 0.7095\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 1s 94us/step - loss: 26.9268 - tip_accuracy: 0.7035 - val_loss: 27.0009 - val_tip_accuracy: 0.7072\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 1s 96us/step - loss: 26.7791 - tip_accuracy: 0.7069 - val_loss: 27.2217 - val_tip_accuracy: 0.6972\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 1s 95us/step - loss: 26.6227 - tip_accuracy: 0.7067 - val_loss: 26.9624 - val_tip_accuracy: 0.7072\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 1s 95us/step - loss: 26.5551 - tip_accuracy: 0.7107 - val_loss: 26.9295 - val_tip_accuracy: 0.7111\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 1s 92us/step - loss: 26.4973 - tip_accuracy: 0.7104 - val_loss: 27.1006 - val_tip_accuracy: 0.7097\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 1s 91us/step - loss: 26.3939 - tip_accuracy: 0.7127 - val_loss: 26.9997 - val_tip_accuracy: 0.7089\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 1s 99us/step - loss: 26.2817 - tip_accuracy: 0.7135 - val_loss: 26.8712 - val_tip_accuracy: 0.7081\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 1s 93us/step - loss: 26.2269 - tip_accuracy: 0.7172 - val_loss: 26.9666 - val_tip_accuracy: 0.7058\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 1s 97us/step - loss: 26.1793 - tip_accuracy: 0.7171 - val_loss: 27.0991 - val_tip_accuracy: 0.7086\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 1s 95us/step - loss: 26.1340 - tip_accuracy: 0.7186 - val_loss: 26.9392 - val_tip_accuracy: 0.7111\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 1s 100us/step - loss: 26.0747 - tip_accuracy: 0.7186 - val_loss: 27.0216 - val_tip_accuracy: 0.7109\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 1s 94us/step - loss: 26.0099 - tip_accuracy: 0.7175 - val_loss: 26.7898 - val_tip_accuracy: 0.7114\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 1s 93us/step - loss: 25.9655 - tip_accuracy: 0.7219 - val_loss: 26.8496 - val_tip_accuracy: 0.7070\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 1s 96us/step - loss: 25.9003 - tip_accuracy: 0.7219 - val_loss: 26.9937 - val_tip_accuracy: 0.7081\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 1s 94us/step - loss: 25.8205 - tip_accuracy: 0.7201 - val_loss: 26.9362 - val_tip_accuracy: 0.7070\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 1s 101us/step - loss: 25.8239 - tip_accuracy: 0.7212 - val_loss: 26.8926 - val_tip_accuracy: 0.7100\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 1s 99us/step - loss: 25.7737 - tip_accuracy: 0.7226 - val_loss: 26.8375 - val_tip_accuracy: 0.7084\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 1s 96us/step - loss: 25.6701 - tip_accuracy: 0.7248 - val_loss: 26.9568 - val_tip_accuracy: 0.7097\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 1s 99us/step - loss: 25.6947 - tip_accuracy: 0.7242 - val_loss: 26.9084 - val_tip_accuracy: 0.7061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3590 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 3s 200us/step - loss: 28.2696 - tip_accuracy: 0.6836 - val_loss: 27.1947 - val_tip_accuracy: 0.6983\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 1s 96us/step - loss: 27.0447 - tip_accuracy: 0.7019 - val_loss: 27.0393 - val_tip_accuracy: 0.7078\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 1s 102us/step - loss: 26.9343 - tip_accuracy: 0.7068 - val_loss: 27.0392 - val_tip_accuracy: 0.7089\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 1s 99us/step - loss: 26.7330 - tip_accuracy: 0.7088 - val_loss: 27.1097 - val_tip_accuracy: 0.7070\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 1s 95us/step - loss: 26.6513 - tip_accuracy: 0.7084 - val_loss: 26.9342 - val_tip_accuracy: 0.7084\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 2s 122us/step - loss: 26.5660 - tip_accuracy: 0.7131 - val_loss: 26.9553 - val_tip_accuracy: 0.7075\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 2s 105us/step - loss: 26.5164 - tip_accuracy: 0.7127 - val_loss: 27.0116 - val_tip_accuracy: 0.7058\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 1s 96us/step - loss: 26.4015 - tip_accuracy: 0.7150 - val_loss: 26.9910 - val_tip_accuracy: 0.7050\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 1s 94us/step - loss: 26.3015 - tip_accuracy: 0.7161 - val_loss: 26.9158 - val_tip_accuracy: 0.7072\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 1s 95us/step - loss: 26.2709 - tip_accuracy: 0.7143 - val_loss: 26.8631 - val_tip_accuracy: 0.7056\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 1s 102us/step - loss: 26.2597 - tip_accuracy: 0.7190 - val_loss: 26.8033 - val_tip_accuracy: 0.7106\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 2s 110us/step - loss: 26.1926 - tip_accuracy: 0.7169 - val_loss: 26.9682 - val_tip_accuracy: 0.7047\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 2s 115us/step - loss: 26.0865 - tip_accuracy: 0.7193 - val_loss: 26.8438 - val_tip_accuracy: 0.7067\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 2s 107us/step - loss: 26.0856 - tip_accuracy: 0.7187 - val_loss: 26.8286 - val_tip_accuracy: 0.7064\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 1s 100us/step - loss: 26.0937 - tip_accuracy: 0.7182 - val_loss: 26.9855 - val_tip_accuracy: 0.7033\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 1s 100us/step - loss: 26.0057 - tip_accuracy: 0.7248 - val_loss: 26.8553 - val_tip_accuracy: 0.7070\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 1s 95us/step - loss: 25.9246 - tip_accuracy: 0.7198 - val_loss: 26.9068 - val_tip_accuracy: 0.7086\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 1s 103us/step - loss: 25.8834 - tip_accuracy: 0.7224 - val_loss: 26.9690 - val_tip_accuracy: 0.7047\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 1s 96us/step - loss: 25.8429 - tip_accuracy: 0.7210 - val_loss: 26.8804 - val_tip_accuracy: 0.7106\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 1s 99us/step - loss: 25.8462 - tip_accuracy: 0.7240 - val_loss: 26.8973 - val_tip_accuracy: 0.7081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3591 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 3s 207us/step - loss: 28.0437 - tip_accuracy: 0.6822 - val_loss: 27.1151 - val_tip_accuracy: 0.7082\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 1s 94us/step - loss: 26.8948 - tip_accuracy: 0.7021 - val_loss: 26.9887 - val_tip_accuracy: 0.7096\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 1s 94us/step - loss: 26.7159 - tip_accuracy: 0.7026 - val_loss: 27.2089 - val_tip_accuracy: 0.7082\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 1s 99us/step - loss: 26.6408 - tip_accuracy: 0.7073 - val_loss: 27.0333 - val_tip_accuracy: 0.7079\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 1s 96us/step - loss: 26.4657 - tip_accuracy: 0.7081 - val_loss: 27.0067 - val_tip_accuracy: 0.7084\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 1s 98us/step - loss: 26.3620 - tip_accuracy: 0.7100 - val_loss: 26.8597 - val_tip_accuracy: 0.7104\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 1s 99us/step - loss: 26.3304 - tip_accuracy: 0.7081 - val_loss: 26.8524 - val_tip_accuracy: 0.7107\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 1s 104us/step - loss: 26.2011 - tip_accuracy: 0.7148 - val_loss: 26.8615 - val_tip_accuracy: 0.7143\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 2s 127us/step - loss: 26.2285 - tip_accuracy: 0.7162 - val_loss: 26.8385 - val_tip_accuracy: 0.7143\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 2s 120us/step - loss: 26.1063 - tip_accuracy: 0.7160 - val_loss: 26.9109 - val_tip_accuracy: 0.7135\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 2s 121us/step - loss: 26.0067 - tip_accuracy: 0.7174 - val_loss: 26.8355 - val_tip_accuracy: 0.7098\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 2s 106us/step - loss: 25.9994 - tip_accuracy: 0.7192 - val_loss: 26.9145 - val_tip_accuracy: 0.7070\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 2s 123us/step - loss: 25.8838 - tip_accuracy: 0.7210 - val_loss: 26.6439 - val_tip_accuracy: 0.7068\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 2s 106us/step - loss: 25.8449 - tip_accuracy: 0.7224 - val_loss: 26.8637 - val_tip_accuracy: 0.7084\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 1s 100us/step - loss: 25.7974 - tip_accuracy: 0.7254 - val_loss: 26.8286 - val_tip_accuracy: 0.7062\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 1s 101us/step - loss: 25.6992 - tip_accuracy: 0.7286 - val_loss: 26.8075 - val_tip_accuracy: 0.7098\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 1s 97us/step - loss: 25.6055 - tip_accuracy: 0.7290 - val_loss: 26.9845 - val_tip_accuracy: 0.7104\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 1s 95us/step - loss: 25.5989 - tip_accuracy: 0.7257 - val_loss: 26.8336 - val_tip_accuracy: 0.7101\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 1s 96us/step - loss: 25.5448 - tip_accuracy: 0.7269 - val_loss: 26.9028 - val_tip_accuracy: 0.7123\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 1s 103us/step - loss: 25.5515 - tip_accuracy: 0.7279 - val_loss: 26.8854 - val_tip_accuracy: 0.7076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3591 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 3s 215us/step - loss: 28.0131 - tip_accuracy: 0.6788 - val_loss: 27.2427 - val_tip_accuracy: 0.7101\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 1s 101us/step - loss: 26.8188 - tip_accuracy: 0.7081 - val_loss: 27.1232 - val_tip_accuracy: 0.6981\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 1s 102us/step - loss: 26.6030 - tip_accuracy: 0.7111 - val_loss: 26.9239 - val_tip_accuracy: 0.7037\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 1s 101us/step - loss: 26.5227 - tip_accuracy: 0.7120 - val_loss: 27.0137 - val_tip_accuracy: 0.7059\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 1s 99us/step - loss: 26.5004 - tip_accuracy: 0.7097 - val_loss: 26.9321 - val_tip_accuracy: 0.7057\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 2s 105us/step - loss: 26.4173 - tip_accuracy: 0.7125 - val_loss: 26.9885 - val_tip_accuracy: 0.7107\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 1s 101us/step - loss: 26.2560 - tip_accuracy: 0.7158 - val_loss: 27.2430 - val_tip_accuracy: 0.7096\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 1s 100us/step - loss: 26.1796 - tip_accuracy: 0.7175 - val_loss: 26.8660 - val_tip_accuracy: 0.7104\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 1s 101us/step - loss: 26.0943 - tip_accuracy: 0.7198 - val_loss: 27.1576 - val_tip_accuracy: 0.7126\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 1s 104us/step - loss: 26.0413 - tip_accuracy: 0.7176 - val_loss: 26.9593 - val_tip_accuracy: 0.7107\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 1s 104us/step - loss: 26.0060 - tip_accuracy: 0.7201 - val_loss: 26.9772 - val_tip_accuracy: 0.7018\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 1s 103us/step - loss: 25.9003 - tip_accuracy: 0.7203 - val_loss: 27.0049 - val_tip_accuracy: 0.7107\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 1s 100us/step - loss: 25.9075 - tip_accuracy: 0.7233 - val_loss: 27.2535 - val_tip_accuracy: 0.7015\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 2s 105us/step - loss: 25.7634 - tip_accuracy: 0.7251 - val_loss: 27.0280 - val_tip_accuracy: 0.7126\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 1s 100us/step - loss: 25.7551 - tip_accuracy: 0.7264 - val_loss: 27.0714 - val_tip_accuracy: 0.7121\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 1s 104us/step - loss: 25.6785 - tip_accuracy: 0.7258 - val_loss: 27.4953 - val_tip_accuracy: 0.7104\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 1s 104us/step - loss: 25.7100 - tip_accuracy: 0.7302 - val_loss: 26.8821 - val_tip_accuracy: 0.7093\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 2s 110us/step - loss: 25.6599 - tip_accuracy: 0.7260 - val_loss: 27.1143 - val_tip_accuracy: 0.7026\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 1s 100us/step - loss: 25.5310 - tip_accuracy: 0.7320 - val_loss: 27.2016 - val_tip_accuracy: 0.7093\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 1s 101us/step - loss: 25.5119 - tip_accuracy: 0.7288 - val_loss: 27.1940 - val_tip_accuracy: 0.7126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3590 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 3s 224us/step - loss: 28.1916 - tip_accuracy: 0.6825 - val_loss: 27.5036 - val_tip_accuracy: 0.6972\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 2s 107us/step - loss: 27.1005 - tip_accuracy: 0.6978 - val_loss: 27.0897 - val_tip_accuracy: 0.7075\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 2s 105us/step - loss: 26.8701 - tip_accuracy: 0.7040 - val_loss: 27.2192 - val_tip_accuracy: 0.7109\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 2s 112us/step - loss: 26.7487 - tip_accuracy: 0.7086 - val_loss: 27.2478 - val_tip_accuracy: 0.7042\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 2s 132us/step - loss: 26.6103 - tip_accuracy: 0.7074 - val_loss: 26.9113 - val_tip_accuracy: 0.7109\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 2s 110us/step - loss: 26.6459 - tip_accuracy: 0.7082 - val_loss: 26.9534 - val_tip_accuracy: 0.7078\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 2s 107us/step - loss: 26.4965 - tip_accuracy: 0.7123 - val_loss: 26.9639 - val_tip_accuracy: 0.7106\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 2s 109us/step - loss: 26.4119 - tip_accuracy: 0.7093 - val_loss: 26.9573 - val_tip_accuracy: 0.7136\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 2s 107us/step - loss: 26.3800 - tip_accuracy: 0.7118 - val_loss: 27.0433 - val_tip_accuracy: 0.7123\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 2s 106us/step - loss: 26.3201 - tip_accuracy: 0.7155 - val_loss: 26.8368 - val_tip_accuracy: 0.7097\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 2s 109us/step - loss: 26.1730 - tip_accuracy: 0.7201 - val_loss: 26.9882 - val_tip_accuracy: 0.7084\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 2s 112us/step - loss: 26.1491 - tip_accuracy: 0.7190 - val_loss: 27.1301 - val_tip_accuracy: 0.7095\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 2s 109us/step - loss: 26.1335 - tip_accuracy: 0.7187 - val_loss: 26.9029 - val_tip_accuracy: 0.7123\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 3s 182us/step - loss: 26.0676 - tip_accuracy: 0.7197 - val_loss: 26.9056 - val_tip_accuracy: 0.7123\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 2s 114us/step - loss: 26.0033 - tip_accuracy: 0.7205 - val_loss: 26.7979 - val_tip_accuracy: 0.7139\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 2s 111us/step - loss: 25.9722 - tip_accuracy: 0.7200 - val_loss: 26.8789 - val_tip_accuracy: 0.7089\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 2s 113us/step - loss: 25.9430 - tip_accuracy: 0.7227 - val_loss: 26.8910 - val_tip_accuracy: 0.7084\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 2s 109us/step - loss: 25.8841 - tip_accuracy: 0.7219 - val_loss: 27.0556 - val_tip_accuracy: 0.7095\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 2s 137us/step - loss: 25.7906 - tip_accuracy: 0.7242 - val_loss: 26.9295 - val_tip_accuracy: 0.7053\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 2s 124us/step - loss: 25.7467 - tip_accuracy: 0.7255 - val_loss: 26.9068 - val_tip_accuracy: 0.7095\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3590 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 3s 242us/step - loss: 28.2888 - tip_accuracy: 0.6838 - val_loss: 27.0949 - val_tip_accuracy: 0.7042\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 2s 112us/step - loss: 26.9089 - tip_accuracy: 0.7049 - val_loss: 26.9817 - val_tip_accuracy: 0.7100\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 2s 106us/step - loss: 26.7538 - tip_accuracy: 0.7043 - val_loss: 26.9287 - val_tip_accuracy: 0.7070\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 2s 105us/step - loss: 26.6451 - tip_accuracy: 0.7073 - val_loss: 27.0139 - val_tip_accuracy: 0.7095\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 2s 107us/step - loss: 26.5133 - tip_accuracy: 0.7122 - val_loss: 26.8841 - val_tip_accuracy: 0.7064\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 2s 110us/step - loss: 26.4259 - tip_accuracy: 0.7140 - val_loss: 26.8898 - val_tip_accuracy: 0.7092\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 2s 113us/step - loss: 26.2823 - tip_accuracy: 0.7153 - val_loss: 27.1325 - val_tip_accuracy: 0.7064\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 2s 107us/step - loss: 26.2616 - tip_accuracy: 0.7157 - val_loss: 26.7039 - val_tip_accuracy: 0.7095\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 2s 116us/step - loss: 26.1722 - tip_accuracy: 0.7161 - val_loss: 26.8082 - val_tip_accuracy: 0.7078\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 1s 102us/step - loss: 26.1349 - tip_accuracy: 0.7166 - val_loss: 26.8041 - val_tip_accuracy: 0.7084\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 2s 108us/step - loss: 26.0322 - tip_accuracy: 0.7183 - val_loss: 26.7836 - val_tip_accuracy: 0.7061\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 2s 107us/step - loss: 26.0660 - tip_accuracy: 0.7171 - val_loss: 26.7740 - val_tip_accuracy: 0.7072\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 2s 111us/step - loss: 25.9795 - tip_accuracy: 0.7203 - val_loss: 26.9560 - val_tip_accuracy: 0.7053\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 2s 108us/step - loss: 25.9286 - tip_accuracy: 0.7207 - val_loss: 26.8850 - val_tip_accuracy: 0.7078\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 2s 127us/step - loss: 25.9245 - tip_accuracy: 0.7180 - val_loss: 26.8758 - val_tip_accuracy: 0.7109\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 2s 110us/step - loss: 25.8208 - tip_accuracy: 0.7225 - val_loss: 26.8227 - val_tip_accuracy: 0.7028\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 2s 121us/step - loss: 25.7510 - tip_accuracy: 0.7251 - val_loss: 26.8270 - val_tip_accuracy: 0.7117\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 2s 141us/step - loss: 25.7052 - tip_accuracy: 0.7273 - val_loss: 26.6926 - val_tip_accuracy: 0.7050\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 2s 144us/step - loss: 25.6814 - tip_accuracy: 0.7211 - val_loss: 26.8469 - val_tip_accuracy: 0.7092\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 2s 147us/step - loss: 25.6813 - tip_accuracy: 0.7273 - val_loss: 26.8866 - val_tip_accuracy: 0.7092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3590 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 4s 280us/step - loss: 28.3524 - tip_accuracy: 0.6795 - val_loss: 27.2057 - val_tip_accuracy: 0.6997\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 2s 120us/step - loss: 27.0466 - tip_accuracy: 0.7050 - val_loss: 26.9530 - val_tip_accuracy: 0.7028\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 2s 141us/step - loss: 26.8386 - tip_accuracy: 0.7077 - val_loss: 27.0408 - val_tip_accuracy: 0.7047\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 2s 129us/step - loss: 26.7784 - tip_accuracy: 0.7084 - val_loss: 26.8971 - val_tip_accuracy: 0.7072\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 2s 127us/step - loss: 26.5851 - tip_accuracy: 0.7120 - val_loss: 26.8519 - val_tip_accuracy: 0.7064\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 2s 125us/step - loss: 26.5148 - tip_accuracy: 0.7142 - val_loss: 26.8004 - val_tip_accuracy: 0.7061\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 2s 128us/step - loss: 26.5025 - tip_accuracy: 0.7146 - val_loss: 27.0262 - val_tip_accuracy: 0.7033\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 2s 122us/step - loss: 26.3655 - tip_accuracy: 0.7157 - val_loss: 26.7830 - val_tip_accuracy: 0.7070\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 2s 119us/step - loss: 26.3328 - tip_accuracy: 0.7156 - val_loss: 26.7941 - val_tip_accuracy: 0.7058\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 2s 122us/step - loss: 26.2448 - tip_accuracy: 0.7182 - val_loss: 26.9640 - val_tip_accuracy: 0.7075\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 2s 124us/step - loss: 26.1920 - tip_accuracy: 0.7174 - val_loss: 27.0548 - val_tip_accuracy: 0.7075\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 2s 125us/step - loss: 26.1693 - tip_accuracy: 0.7172 - val_loss: 26.7856 - val_tip_accuracy: 0.7086\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 2s 124us/step - loss: 26.1240 - tip_accuracy: 0.7192 - val_loss: 26.7301 - val_tip_accuracy: 0.7114\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 2s 127us/step - loss: 26.0867 - tip_accuracy: 0.7210 - val_loss: 26.8537 - val_tip_accuracy: 0.7061\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 2s 121us/step - loss: 25.9561 - tip_accuracy: 0.7205 - val_loss: 27.1536 - val_tip_accuracy: 0.7039\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 2s 117us/step - loss: 25.9699 - tip_accuracy: 0.7214 - val_loss: 26.8969 - val_tip_accuracy: 0.7064\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 2s 118us/step - loss: 25.9143 - tip_accuracy: 0.7247 - val_loss: 26.8239 - val_tip_accuracy: 0.7114\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 2s 134us/step - loss: 25.8192 - tip_accuracy: 0.7249 - val_loss: 27.0620 - val_tip_accuracy: 0.7081\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 2s 119us/step - loss: 25.7742 - tip_accuracy: 0.7251 - val_loss: 26.8532 - val_tip_accuracy: 0.7111\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 2s 121us/step - loss: 25.7338 - tip_accuracy: 0.7242 - val_loss: 27.0047 - val_tip_accuracy: 0.7072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3591 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 4s 247us/step - loss: 28.0454 - tip_accuracy: 0.6808 - val_loss: 27.2295 - val_tip_accuracy: 0.7012\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 2s 116us/step - loss: 26.8472 - tip_accuracy: 0.7025 - val_loss: 26.8897 - val_tip_accuracy: 0.7098\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 2s 111us/step - loss: 26.6474 - tip_accuracy: 0.7057 - val_loss: 26.9607 - val_tip_accuracy: 0.7070\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 2s 114us/step - loss: 26.5422 - tip_accuracy: 0.7093 - val_loss: 26.8921 - val_tip_accuracy: 0.7082\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 2s 113us/step - loss: 26.4410 - tip_accuracy: 0.7096 - val_loss: 26.9500 - val_tip_accuracy: 0.7059\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 2s 119us/step - loss: 26.3603 - tip_accuracy: 0.7135 - val_loss: 26.7915 - val_tip_accuracy: 0.7121\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 2s 109us/step - loss: 26.2642 - tip_accuracy: 0.7139 - val_loss: 26.9055 - val_tip_accuracy: 0.7093\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 2s 115us/step - loss: 26.2080 - tip_accuracy: 0.7134 - val_loss: 26.9295 - val_tip_accuracy: 0.7104\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 2s 113us/step - loss: 26.1082 - tip_accuracy: 0.7175 - val_loss: 27.0924 - val_tip_accuracy: 0.7070\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 2s 129us/step - loss: 26.0441 - tip_accuracy: 0.7192 - val_loss: 26.9293 - val_tip_accuracy: 0.7045\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 2s 130us/step - loss: 26.0069 - tip_accuracy: 0.7181 - val_loss: 26.7873 - val_tip_accuracy: 0.7096\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 2s 119us/step - loss: 25.9280 - tip_accuracy: 0.7200 - val_loss: 26.8361 - val_tip_accuracy: 0.7057\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 2s 112us/step - loss: 25.8974 - tip_accuracy: 0.7195 - val_loss: 27.0099 - val_tip_accuracy: 0.7057\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 2s 114us/step - loss: 25.8883 - tip_accuracy: 0.7226 - val_loss: 26.9282 - val_tip_accuracy: 0.7109\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 2s 116us/step - loss: 25.7794 - tip_accuracy: 0.7231 - val_loss: 26.8803 - val_tip_accuracy: 0.7098\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 2s 124us/step - loss: 25.6810 - tip_accuracy: 0.7224 - val_loss: 26.9595 - val_tip_accuracy: 0.7115\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 2s 112us/step - loss: 25.6487 - tip_accuracy: 0.7259 - val_loss: 27.0326 - val_tip_accuracy: 0.7084\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 2s 113us/step - loss: 25.5599 - tip_accuracy: 0.7241 - val_loss: 27.1300 - val_tip_accuracy: 0.7059\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 2s 117us/step - loss: 25.5968 - tip_accuracy: 0.7261 - val_loss: 27.0763 - val_tip_accuracy: 0.7043\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 2s 112us/step - loss: 25.5577 - tip_accuracy: 0.7299 - val_loss: 26.9938 - val_tip_accuracy: 0.7057\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 14360 samples, validate on 3591 samples\n",
      "Epoch 1/20\n",
      "14360/14360 [==============================] - 4s 269us/step - loss: 28.1065 - tip_accuracy: 0.6779 - val_loss: 27.2239 - val_tip_accuracy: 0.7051\n",
      "Epoch 2/20\n",
      "14360/14360 [==============================] - 2s 116us/step - loss: 26.8492 - tip_accuracy: 0.7015 - val_loss: 26.9554 - val_tip_accuracy: 0.6959\n",
      "Epoch 3/20\n",
      "14360/14360 [==============================] - 2s 151us/step - loss: 26.7009 - tip_accuracy: 0.7047 - val_loss: 27.0662 - val_tip_accuracy: 0.6967\n",
      "Epoch 4/20\n",
      "14360/14360 [==============================] - 2s 136us/step - loss: 26.6158 - tip_accuracy: 0.7076 - val_loss: 27.0051 - val_tip_accuracy: 0.7018\n",
      "Epoch 5/20\n",
      "14360/14360 [==============================] - 2s 121us/step - loss: 26.4701 - tip_accuracy: 0.7098 - val_loss: 27.1201 - val_tip_accuracy: 0.7009\n",
      "Epoch 6/20\n",
      "14360/14360 [==============================] - 2s 119us/step - loss: 26.4526 - tip_accuracy: 0.7099 - val_loss: 27.0548 - val_tip_accuracy: 0.7065\n",
      "Epoch 7/20\n",
      "14360/14360 [==============================] - 2s 131us/step - loss: 26.2889 - tip_accuracy: 0.7123 - val_loss: 26.8763 - val_tip_accuracy: 0.7031\n",
      "Epoch 8/20\n",
      "14360/14360 [==============================] - 2s 150us/step - loss: 26.2475 - tip_accuracy: 0.7131 - val_loss: 26.8681 - val_tip_accuracy: 0.7023\n",
      "Epoch 9/20\n",
      "14360/14360 [==============================] - 2s 136us/step - loss: 26.1891 - tip_accuracy: 0.7145 - val_loss: 26.9856 - val_tip_accuracy: 0.7059\n",
      "Epoch 10/20\n",
      "14360/14360 [==============================] - 2s 138us/step - loss: 26.1087 - tip_accuracy: 0.7172 - val_loss: 27.0612 - val_tip_accuracy: 0.7045\n",
      "Epoch 11/20\n",
      "14360/14360 [==============================] - 2s 130us/step - loss: 26.0056 - tip_accuracy: 0.7217 - val_loss: 26.9499 - val_tip_accuracy: 0.7012\n",
      "Epoch 12/20\n",
      "14360/14360 [==============================] - 2s 134us/step - loss: 25.9885 - tip_accuracy: 0.7196 - val_loss: 26.8588 - val_tip_accuracy: 0.7043\n",
      "Epoch 13/20\n",
      "14360/14360 [==============================] - 2s 131us/step - loss: 25.9411 - tip_accuracy: 0.7194 - val_loss: 26.9333 - val_tip_accuracy: 0.7043\n",
      "Epoch 14/20\n",
      "14360/14360 [==============================] - 2s 117us/step - loss: 25.7810 - tip_accuracy: 0.7215 - val_loss: 27.0002 - val_tip_accuracy: 0.6979\n",
      "Epoch 15/20\n",
      "14360/14360 [==============================] - 2s 116us/step - loss: 25.8039 - tip_accuracy: 0.7267 - val_loss: 27.0887 - val_tip_accuracy: 0.7023\n",
      "Epoch 16/20\n",
      "14360/14360 [==============================] - 2s 124us/step - loss: 25.8177 - tip_accuracy: 0.7266 - val_loss: 26.9615 - val_tip_accuracy: 0.7018\n",
      "Epoch 17/20\n",
      "14360/14360 [==============================] - 2s 121us/step - loss: 25.7060 - tip_accuracy: 0.7254 - val_loss: 27.0010 - val_tip_accuracy: 0.6981\n",
      "Epoch 18/20\n",
      "14360/14360 [==============================] - 2s 120us/step - loss: 25.6571 - tip_accuracy: 0.7266 - val_loss: 26.9574 - val_tip_accuracy: 0.7006\n",
      "Epoch 19/20\n",
      "14360/14360 [==============================] - 2s 121us/step - loss: 25.6412 - tip_accuracy: 0.7267 - val_loss: 27.0936 - val_tip_accuracy: 0.7023\n",
      "Epoch 20/20\n",
      "14360/14360 [==============================] - 2s 120us/step - loss: 25.5625 - tip_accuracy: 0.7286 - val_loss: 27.1203 - val_tip_accuracy: 0.7037\n",
      "avg_nn done\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error</th>\n",
       "      <th>std_accuracy</th>\n",
       "      <th>std_error</th>\n",
       "      <th>score_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>avg</td>\n",
       "      <td>0.710402</td>\n",
       "      <td>26.493466</td>\n",
       "      <td>0.003271</td>\n",
       "      <td>0.303061</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>avg_nn</td>\n",
       "      <td>0.708530</td>\n",
       "      <td>26.823649</td>\n",
       "      <td>0.004199</td>\n",
       "      <td>0.264216</td>\n",
       "      <td>cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>avg</td>\n",
       "      <td>0.710027</td>\n",
       "      <td>26.431705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>avg_nn</td>\n",
       "      <td>0.702807</td>\n",
       "      <td>26.757783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model  accuracy      error  std_accuracy  std_error score_type\n",
       "0     avg  0.710402  26.493466      0.003271   0.303061         cv\n",
       "1  avg_nn  0.708530  26.823649      0.004199   0.264216         cv\n",
       "2     avg  0.710027  26.431705           NaN        NaN       test\n",
       "3  avg_nn  0.702807  26.757783           NaN        NaN       test"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores = measure_estimators(\n",
    "    [('avg', avg_model, {}),\n",
    "     ('avg_nn', nn_pipe, {'fit_params': {'callbacks': [callbacks.EarlyStopping(monitor='val_loss', patience=3)]}})],\n",
    "    (X_train, X_test, y_train, y_test),\n",
    "    n_jobs=1\n",
    ")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_cv_model_performance(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 21969 samples, validate on 5493 samples\n",
      "Epoch 1/20\n",
      "21969/21969 [==============================] - 2s 99us/step - loss: 27.7259 - tip_accuracy: 0.6739 - val_loss: 27.3979 - val_tip_accuracy: 0.6969\n",
      "Epoch 2/20\n",
      "21969/21969 [==============================] - 2s 82us/step - loss: 26.6001 - tip_accuracy: 0.7048 - val_loss: 27.2635 - val_tip_accuracy: 0.6967\n",
      "Epoch 3/20\n",
      "21969/21969 [==============================] - 2s 90us/step - loss: 26.4392 - tip_accuracy: 0.7074 - val_loss: 27.1444 - val_tip_accuracy: 0.6954\n",
      "Epoch 4/20\n",
      "21969/21969 [==============================] - 2s 82us/step - loss: 26.3241 - tip_accuracy: 0.7080 - val_loss: 27.0727 - val_tip_accuracy: 0.6973\n",
      "Epoch 5/20\n",
      "21969/21969 [==============================] - 2s 70us/step - loss: 26.2522 - tip_accuracy: 0.7084 - val_loss: 27.2354 - val_tip_accuracy: 0.6989\n",
      "Epoch 6/20\n",
      "21969/21969 [==============================] - 2s 77us/step - loss: 26.1357 - tip_accuracy: 0.7093 - val_loss: 27.0671 - val_tip_accuracy: 0.6963\n",
      "Epoch 7/20\n",
      "21969/21969 [==============================] - 2s 76us/step - loss: 26.1055 - tip_accuracy: 0.7114 - val_loss: 27.1873 - val_tip_accuracy: 0.6976\n",
      "Epoch 8/20\n",
      "21969/21969 [==============================] - 2s 80us/step - loss: 26.0143 - tip_accuracy: 0.7137 - val_loss: 27.1465 - val_tip_accuracy: 0.6969\n",
      "Epoch 9/20\n",
      "21969/21969 [==============================] - 2s 90us/step - loss: 25.9648 - tip_accuracy: 0.7140 - val_loss: 27.1352 - val_tip_accuracy: 0.6973\n",
      "Epoch 10/20\n",
      "21969/21969 [==============================] - 2s 82us/step - loss: 25.9041 - tip_accuracy: 0.7148 - val_loss: 27.2753 - val_tip_accuracy: 0.6994\n",
      "Epoch 11/20\n",
      "21969/21969 [==============================] - 2s 83us/step - loss: 25.8518 - tip_accuracy: 0.7155 - val_loss: 27.1252 - val_tip_accuracy: 0.6987\n",
      "Epoch 12/20\n",
      "21969/21969 [==============================] - 2s 75us/step - loss: 25.8286 - tip_accuracy: 0.7161 - val_loss: 27.1645 - val_tip_accuracy: 0.6958\n",
      "Epoch 13/20\n",
      "21969/21969 [==============================] - 2s 77us/step - loss: 25.8253 - tip_accuracy: 0.7174 - val_loss: 27.2390 - val_tip_accuracy: 0.6978\n",
      "Epoch 14/20\n",
      "21969/21969 [==============================] - 2s 75us/step - loss: 25.7179 - tip_accuracy: 0.7176 - val_loss: 27.4331 - val_tip_accuracy: 0.6940\n",
      "Epoch 15/20\n",
      "21969/21969 [==============================] - 2s 73us/step - loss: 25.7004 - tip_accuracy: 0.7202 - val_loss: 27.4002 - val_tip_accuracy: 0.6952\n",
      "Epoch 16/20\n",
      "21969/21969 [==============================] - 2s 81us/step - loss: 25.6598 - tip_accuracy: 0.7208 - val_loss: 27.1969 - val_tip_accuracy: 0.6951\n",
      "Epoch 17/20\n",
      "21969/21969 [==============================] - 2s 76us/step - loss: 25.5842 - tip_accuracy: 0.7185 - val_loss: 27.2247 - val_tip_accuracy: 0.6934\n",
      "Epoch 18/20\n",
      "21969/21969 [==============================] - 2s 75us/step - loss: 25.6454 - tip_accuracy: 0.7222 - val_loss: 27.2395 - val_tip_accuracy: 0.6974\n",
      "Epoch 19/20\n",
      "21969/21969 [==============================] - 2s 75us/step - loss: 25.5505 - tip_accuracy: 0.7198 - val_loss: 27.2524 - val_tip_accuracy: 0.6962\n",
      "Epoch 20/20\n",
      "21969/21969 [==============================] - 2s 73us/step - loss: 25.5370 - tip_accuracy: 0.7202 - val_loss: 27.1338 - val_tip_accuracy: 0.6931\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22281 samples, validate on 5571 samples\n",
      "Epoch 1/20\n",
      "22281/22281 [==============================] - 3s 126us/step - loss: 27.6463 - tip_accuracy: 0.6857 - val_loss: 27.6307 - val_tip_accuracy: 0.6931\n",
      "Epoch 2/20\n",
      "22281/22281 [==============================] - 2s 99us/step - loss: 26.5951 - tip_accuracy: 0.7070 - val_loss: 27.2747 - val_tip_accuracy: 0.6970\n",
      "Epoch 3/20\n",
      "22281/22281 [==============================] - 2s 82us/step - loss: 26.4857 - tip_accuracy: 0.7062 - val_loss: 27.1788 - val_tip_accuracy: 0.6997\n",
      "Epoch 4/20\n",
      "22281/22281 [==============================] - 2s 79us/step - loss: 26.3403 - tip_accuracy: 0.7084 - val_loss: 27.1342 - val_tip_accuracy: 0.6952\n",
      "Epoch 5/20\n",
      "22281/22281 [==============================] - 2s 79us/step - loss: 26.2469 - tip_accuracy: 0.7093 - val_loss: 27.1702 - val_tip_accuracy: 0.6956\n",
      "Epoch 6/20\n",
      "22281/22281 [==============================] - 2s 78us/step - loss: 26.1699 - tip_accuracy: 0.7123 - val_loss: 27.0433 - val_tip_accuracy: 0.6943\n",
      "Epoch 7/20\n",
      "22281/22281 [==============================] - 2s 87us/step - loss: 26.1183 - tip_accuracy: 0.7107 - val_loss: 27.1399 - val_tip_accuracy: 0.6943\n",
      "Epoch 8/20\n",
      "22281/22281 [==============================] - 2s 97us/step - loss: 26.0405 - tip_accuracy: 0.7150 - val_loss: 27.1096 - val_tip_accuracy: 0.6952\n",
      "Epoch 9/20\n",
      "22281/22281 [==============================] - 2s 79us/step - loss: 25.9918 - tip_accuracy: 0.7155 - val_loss: 27.1841 - val_tip_accuracy: 0.6975\n",
      "Epoch 10/20\n",
      "22281/22281 [==============================] - 2s 90us/step - loss: 25.9932 - tip_accuracy: 0.7130 - val_loss: 27.0818 - val_tip_accuracy: 0.6975\n",
      "Epoch 11/20\n",
      "22281/22281 [==============================] - 2s 77us/step - loss: 25.9472 - tip_accuracy: 0.7154 - val_loss: 27.2293 - val_tip_accuracy: 0.6929\n",
      "Epoch 12/20\n",
      "22281/22281 [==============================] - 2s 79us/step - loss: 25.9612 - tip_accuracy: 0.7136 - val_loss: 27.1227 - val_tip_accuracy: 0.6961\n",
      "Epoch 13/20\n",
      "22281/22281 [==============================] - 2s 90us/step - loss: 25.8565 - tip_accuracy: 0.7157 - val_loss: 27.1672 - val_tip_accuracy: 0.6975\n",
      "Epoch 14/20\n",
      "22281/22281 [==============================] - 2s 100us/step - loss: 25.8052 - tip_accuracy: 0.7158 - val_loss: 27.2717 - val_tip_accuracy: 0.6936\n",
      "Epoch 15/20\n",
      "22281/22281 [==============================] - 2s 79us/step - loss: 25.7743 - tip_accuracy: 0.7173 - val_loss: 27.2030 - val_tip_accuracy: 0.6929\n",
      "Epoch 16/20\n",
      "22281/22281 [==============================] - 2s 82us/step - loss: 25.7761 - tip_accuracy: 0.7180 - val_loss: 27.2436 - val_tip_accuracy: 0.6941\n",
      "Epoch 17/20\n",
      "22281/22281 [==============================] - 2s 100us/step - loss: 25.7121 - tip_accuracy: 0.7178 - val_loss: 27.2486 - val_tip_accuracy: 0.7006\n",
      "Epoch 18/20\n",
      "22281/22281 [==============================] - 2s 88us/step - loss: 25.6216 - tip_accuracy: 0.7190 - val_loss: 27.1821 - val_tip_accuracy: 0.6995\n",
      "Epoch 19/20\n",
      "22281/22281 [==============================] - 2s 81us/step - loss: 25.6205 - tip_accuracy: 0.7200 - val_loss: 27.4270 - val_tip_accuracy: 0.6997\n",
      "Epoch 20/20\n",
      "22281/22281 [==============================] - 2s 81us/step - loss: 25.5891 - tip_accuracy: 0.7238 - val_loss: 27.3978 - val_tip_accuracy: 0.6948\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22611 samples, validate on 5653 samples\n",
      "Epoch 1/20\n",
      "22611/22611 [==============================] - 3s 118us/step - loss: 27.6888 - tip_accuracy: 0.6828 - val_loss: 27.4202 - val_tip_accuracy: 0.6970\n",
      "Epoch 2/20\n",
      "22611/22611 [==============================] - 2s 81us/step - loss: 26.6830 - tip_accuracy: 0.7048 - val_loss: 27.1705 - val_tip_accuracy: 0.7037\n",
      "Epoch 3/20\n",
      "22611/22611 [==============================] - 2s 79us/step - loss: 26.5140 - tip_accuracy: 0.7098 - val_loss: 27.2277 - val_tip_accuracy: 0.6973\n",
      "Epoch 4/20\n",
      "22611/22611 [==============================] - 2s 82us/step - loss: 26.4225 - tip_accuracy: 0.7102 - val_loss: 27.3754 - val_tip_accuracy: 0.6956\n",
      "Epoch 5/20\n",
      "22611/22611 [==============================] - 2s 83us/step - loss: 26.2882 - tip_accuracy: 0.7079 - val_loss: 27.1887 - val_tip_accuracy: 0.7016\n",
      "Epoch 6/20\n",
      "22611/22611 [==============================] - 2s 81us/step - loss: 26.2065 - tip_accuracy: 0.7128 - val_loss: 27.3386 - val_tip_accuracy: 0.6952\n",
      "Epoch 7/20\n",
      "22611/22611 [==============================] - 2s 95us/step - loss: 26.2274 - tip_accuracy: 0.7148 - val_loss: 27.2179 - val_tip_accuracy: 0.6989\n",
      "Epoch 8/20\n",
      "22611/22611 [==============================] - 2s 90us/step - loss: 26.0869 - tip_accuracy: 0.7127 - val_loss: 27.1406 - val_tip_accuracy: 0.7021\n",
      "Epoch 9/20\n",
      "22611/22611 [==============================] - 2s 82us/step - loss: 26.0793 - tip_accuracy: 0.7137 - val_loss: 27.3196 - val_tip_accuracy: 0.7003\n",
      "Epoch 10/20\n",
      "22611/22611 [==============================] - 2s 88us/step - loss: 26.0235 - tip_accuracy: 0.7150 - val_loss: 27.2039 - val_tip_accuracy: 0.6996\n",
      "Epoch 11/20\n",
      "22611/22611 [==============================] - 2s 89us/step - loss: 25.9817 - tip_accuracy: 0.7169 - val_loss: 27.3738 - val_tip_accuracy: 0.7003\n",
      "Epoch 12/20\n",
      "22611/22611 [==============================] - 2s 96us/step - loss: 25.9676 - tip_accuracy: 0.7146 - val_loss: 27.2964 - val_tip_accuracy: 0.6986\n",
      "Epoch 13/20\n",
      "22611/22611 [==============================] - 2s 93us/step - loss: 25.8421 - tip_accuracy: 0.7192 - val_loss: 27.1500 - val_tip_accuracy: 0.7010\n",
      "Epoch 14/20\n",
      "22611/22611 [==============================] - 3s 113us/step - loss: 25.8255 - tip_accuracy: 0.7173 - val_loss: 27.4543 - val_tip_accuracy: 0.6991\n",
      "Epoch 15/20\n",
      "22611/22611 [==============================] - 2s 90us/step - loss: 25.8122 - tip_accuracy: 0.7194 - val_loss: 27.3800 - val_tip_accuracy: 0.6995\n",
      "Epoch 16/20\n",
      "22611/22611 [==============================] - 2s 100us/step - loss: 25.8139 - tip_accuracy: 0.7170 - val_loss: 27.3105 - val_tip_accuracy: 0.7000\n",
      "Epoch 17/20\n",
      "22611/22611 [==============================] - 2s 81us/step - loss: 25.7108 - tip_accuracy: 0.7193 - val_loss: 27.2755 - val_tip_accuracy: 0.6973\n",
      "Epoch 18/20\n",
      "22611/22611 [==============================] - 2s 89us/step - loss: 25.7185 - tip_accuracy: 0.7214 - val_loss: 27.3657 - val_tip_accuracy: 0.7010\n",
      "Epoch 19/20\n",
      "22611/22611 [==============================] - 2s 91us/step - loss: 25.6243 - tip_accuracy: 0.7220 - val_loss: 27.3637 - val_tip_accuracy: 0.7003\n",
      "Epoch 20/20\n",
      "22611/22611 [==============================] - 2s 90us/step - loss: 25.6116 - tip_accuracy: 0.7220 - val_loss: 27.3347 - val_tip_accuracy: 0.7012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22942 samples, validate on 5736 samples\n",
      "Epoch 1/20\n",
      "22942/22942 [==============================] - 3s 129us/step - loss: 27.5964 - tip_accuracy: 0.6841 - val_loss: 27.3914 - val_tip_accuracy: 0.6982\n",
      "Epoch 2/20\n",
      "22942/22942 [==============================] - 2s 89us/step - loss: 26.6825 - tip_accuracy: 0.7043 - val_loss: 27.3203 - val_tip_accuracy: 0.6968\n",
      "Epoch 3/20\n",
      "22942/22942 [==============================] - 2s 87us/step - loss: 26.5286 - tip_accuracy: 0.7081 - val_loss: 27.1940 - val_tip_accuracy: 0.7003\n",
      "Epoch 4/20\n",
      "22942/22942 [==============================] - 2s 87us/step - loss: 26.3921 - tip_accuracy: 0.7087 - val_loss: 27.1660 - val_tip_accuracy: 0.7010\n",
      "Epoch 5/20\n",
      "22942/22942 [==============================] - 3s 111us/step - loss: 26.2805 - tip_accuracy: 0.7118 - val_loss: 27.3362 - val_tip_accuracy: 0.6954\n",
      "Epoch 6/20\n",
      "22942/22942 [==============================] - 2s 105us/step - loss: 26.2309 - tip_accuracy: 0.7112 - val_loss: 27.2026 - val_tip_accuracy: 0.7028\n",
      "Epoch 7/20\n",
      "22942/22942 [==============================] - 3s 124us/step - loss: 26.1767 - tip_accuracy: 0.7134 - val_loss: 27.0825 - val_tip_accuracy: 0.7035\n",
      "Epoch 8/20\n",
      "22942/22942 [==============================] - 2s 94us/step - loss: 26.1155 - tip_accuracy: 0.7166 - val_loss: 27.2576 - val_tip_accuracy: 0.6970\n",
      "Epoch 9/20\n",
      "22942/22942 [==============================] - 2s 103us/step - loss: 26.0487 - tip_accuracy: 0.7161 - val_loss: 27.1515 - val_tip_accuracy: 0.6996\n",
      "Epoch 10/20\n",
      "22942/22942 [==============================] - 2s 88us/step - loss: 26.0372 - tip_accuracy: 0.7154 - val_loss: 27.0906 - val_tip_accuracy: 0.7026\n",
      "Epoch 11/20\n",
      "22942/22942 [==============================] - 2s 88us/step - loss: 25.9498 - tip_accuracy: 0.7174 - val_loss: 27.2277 - val_tip_accuracy: 0.7033\n",
      "Epoch 12/20\n",
      "22942/22942 [==============================] - 2s 86us/step - loss: 25.8740 - tip_accuracy: 0.7166 - val_loss: 27.1917 - val_tip_accuracy: 0.7012\n",
      "Epoch 13/20\n",
      "22942/22942 [==============================] - 2s 88us/step - loss: 25.8506 - tip_accuracy: 0.7190 - val_loss: 27.3506 - val_tip_accuracy: 0.7019\n",
      "Epoch 14/20\n",
      "22942/22942 [==============================] - 2s 104us/step - loss: 25.8474 - tip_accuracy: 0.7194 - val_loss: 27.2980 - val_tip_accuracy: 0.7022\n",
      "Epoch 15/20\n",
      "22942/22942 [==============================] - 2s 89us/step - loss: 25.7573 - tip_accuracy: 0.7203 - val_loss: 27.3999 - val_tip_accuracy: 0.7040\n",
      "Epoch 16/20\n",
      "22942/22942 [==============================] - 2s 89us/step - loss: 25.7382 - tip_accuracy: 0.7239 - val_loss: 27.1439 - val_tip_accuracy: 0.7026\n",
      "Epoch 17/20\n",
      "22942/22942 [==============================] - 2s 101us/step - loss: 25.6407 - tip_accuracy: 0.7207 - val_loss: 27.3480 - val_tip_accuracy: 0.7029\n",
      "Epoch 18/20\n",
      "22942/22942 [==============================] - 2s 92us/step - loss: 25.6755 - tip_accuracy: 0.7223 - val_loss: 27.2076 - val_tip_accuracy: 0.7019\n",
      "Epoch 19/20\n",
      "22942/22942 [==============================] - 2s 91us/step - loss: 25.5994 - tip_accuracy: 0.7243 - val_loss: 27.3660 - val_tip_accuracy: 0.7012\n",
      "Epoch 20/20\n",
      "22942/22942 [==============================] - 2s 89us/step - loss: 25.6217 - tip_accuracy: 0.7226 - val_loss: 27.2552 - val_tip_accuracy: 0.6960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23273 samples, validate on 5819 samples\n",
      "Epoch 1/20\n",
      "23273/23273 [==============================] - 3s 136us/step - loss: 27.7043 - tip_accuracy: 0.6884 - val_loss: 27.2144 - val_tip_accuracy: 0.7017\n",
      "Epoch 2/20\n",
      "23273/23273 [==============================] - 2s 91us/step - loss: 26.7091 - tip_accuracy: 0.7036 - val_loss: 27.2171 - val_tip_accuracy: 0.6977\n",
      "Epoch 3/20\n",
      "23273/23273 [==============================] - 2s 105us/step - loss: 26.5837 - tip_accuracy: 0.7086 - val_loss: 27.4374 - val_tip_accuracy: 0.6955\n",
      "Epoch 4/20\n",
      "23273/23273 [==============================] - 3s 108us/step - loss: 26.4892 - tip_accuracy: 0.7072 - val_loss: 27.3143 - val_tip_accuracy: 0.7003\n",
      "Epoch 5/20\n",
      "23273/23273 [==============================] - 3s 109us/step - loss: 26.3596 - tip_accuracy: 0.7116 - val_loss: 27.3170 - val_tip_accuracy: 0.7006\n",
      "Epoch 6/20\n",
      "23273/23273 [==============================] - 2s 92us/step - loss: 26.2803 - tip_accuracy: 0.7115 - val_loss: 27.0838 - val_tip_accuracy: 0.6998\n",
      "Epoch 7/20\n",
      "23273/23273 [==============================] - 2s 100us/step - loss: 26.2063 - tip_accuracy: 0.7119 - val_loss: 27.1543 - val_tip_accuracy: 0.6999\n",
      "Epoch 8/20\n",
      "23273/23273 [==============================] - 2s 103us/step - loss: 26.1530 - tip_accuracy: 0.7137 - val_loss: 27.2803 - val_tip_accuracy: 0.7027\n",
      "Epoch 9/20\n",
      "23273/23273 [==============================] - 3s 108us/step - loss: 26.1360 - tip_accuracy: 0.7177 - val_loss: 27.1727 - val_tip_accuracy: 0.7017\n",
      "Epoch 10/20\n",
      "23273/23273 [==============================] - 2s 97us/step - loss: 26.0619 - tip_accuracy: 0.7177 - val_loss: 27.1445 - val_tip_accuracy: 0.7027\n",
      "Epoch 11/20\n",
      "23273/23273 [==============================] - 2s 91us/step - loss: 26.0627 - tip_accuracy: 0.7149 - val_loss: 27.1652 - val_tip_accuracy: 0.7034\n",
      "Epoch 12/20\n",
      "23273/23273 [==============================] - 2s 90us/step - loss: 26.0590 - tip_accuracy: 0.7161 - val_loss: 27.1509 - val_tip_accuracy: 0.7054\n",
      "Epoch 13/20\n",
      "23273/23273 [==============================] - 2s 94us/step - loss: 25.9612 - tip_accuracy: 0.7198 - val_loss: 27.1944 - val_tip_accuracy: 0.7032\n",
      "Epoch 14/20\n",
      "23273/23273 [==============================] - 3s 113us/step - loss: 25.8834 - tip_accuracy: 0.7188 - val_loss: 27.2473 - val_tip_accuracy: 0.7005\n",
      "Epoch 15/20\n",
      "23273/23273 [==============================] - 2s 96us/step - loss: 25.8996 - tip_accuracy: 0.7189 - val_loss: 27.2889 - val_tip_accuracy: 0.6996\n",
      "Epoch 16/20\n",
      "23273/23273 [==============================] - 2s 92us/step - loss: 25.8167 - tip_accuracy: 0.7211 - val_loss: 27.3200 - val_tip_accuracy: 0.7025\n",
      "Epoch 17/20\n",
      "23273/23273 [==============================] - 2s 89us/step - loss: 25.7870 - tip_accuracy: 0.7212 - val_loss: 27.3033 - val_tip_accuracy: 0.7061\n",
      "Epoch 18/20\n",
      "23273/23273 [==============================] - 2s 90us/step - loss: 25.7959 - tip_accuracy: 0.7219 - val_loss: 27.2971 - val_tip_accuracy: 0.7005\n",
      "Epoch 19/20\n",
      "23273/23273 [==============================] - 2s 89us/step - loss: 25.7407 - tip_accuracy: 0.7223 - val_loss: 27.3051 - val_tip_accuracy: 0.7010\n",
      "Epoch 20/20\n",
      "23273/23273 [==============================] - 2s 89us/step - loss: 25.7340 - tip_accuracy: 0.7216 - val_loss: 27.5045 - val_tip_accuracy: 0.7012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23603 samples, validate on 5901 samples\n",
      "Epoch 1/20\n",
      "23603/23603 [==============================] - 3s 145us/step - loss: 27.7286 - tip_accuracy: 0.6873 - val_loss: 27.3400 - val_tip_accuracy: 0.7012\n",
      "Epoch 2/20\n",
      "23603/23603 [==============================] - 2s 94us/step - loss: 26.7827 - tip_accuracy: 0.7029 - val_loss: 27.4114 - val_tip_accuracy: 0.7023\n",
      "Epoch 3/20\n",
      "23603/23603 [==============================] - 2s 93us/step - loss: 26.6062 - tip_accuracy: 0.7077 - val_loss: 27.2975 - val_tip_accuracy: 0.6999\n",
      "Epoch 4/20\n",
      "23603/23603 [==============================] - 2s 92us/step - loss: 26.5298 - tip_accuracy: 0.7093 - val_loss: 27.1670 - val_tip_accuracy: 0.7028\n",
      "Epoch 5/20\n",
      "23603/23603 [==============================] - 2s 94us/step - loss: 26.4527 - tip_accuracy: 0.7128 - val_loss: 27.2881 - val_tip_accuracy: 0.7001\n",
      "Epoch 6/20\n",
      "23603/23603 [==============================] - 2s 93us/step - loss: 26.3278 - tip_accuracy: 0.7110 - val_loss: 27.3342 - val_tip_accuracy: 0.7017\n",
      "Epoch 7/20\n",
      "23603/23603 [==============================] - 2s 91us/step - loss: 26.2627 - tip_accuracy: 0.7126 - val_loss: 27.3737 - val_tip_accuracy: 0.7014\n",
      "Epoch 8/20\n",
      "23603/23603 [==============================] - 2s 95us/step - loss: 26.2058 - tip_accuracy: 0.7116 - val_loss: 27.1494 - val_tip_accuracy: 0.7034\n",
      "Epoch 9/20\n",
      "23603/23603 [==============================] - 2s 90us/step - loss: 26.2534 - tip_accuracy: 0.7127 - val_loss: 27.1197 - val_tip_accuracy: 0.7063\n",
      "Epoch 10/20\n",
      "23603/23603 [==============================] - 2s 92us/step - loss: 26.1215 - tip_accuracy: 0.7164 - val_loss: 27.1159 - val_tip_accuracy: 0.7050\n",
      "Epoch 11/20\n",
      "23603/23603 [==============================] - 2s 93us/step - loss: 26.1056 - tip_accuracy: 0.7155 - val_loss: 27.0791 - val_tip_accuracy: 0.7090\n",
      "Epoch 12/20\n",
      "23603/23603 [==============================] - 2s 93us/step - loss: 26.0221 - tip_accuracy: 0.7189 - val_loss: 27.3094 - val_tip_accuracy: 0.7019\n",
      "Epoch 13/20\n",
      "23603/23603 [==============================] - 2s 91us/step - loss: 26.0753 - tip_accuracy: 0.7159 - val_loss: 27.2592 - val_tip_accuracy: 0.7055\n",
      "Epoch 14/20\n",
      "23603/23603 [==============================] - 2s 93us/step - loss: 25.9649 - tip_accuracy: 0.7168 - val_loss: 27.4222 - val_tip_accuracy: 0.7048\n",
      "Epoch 15/20\n",
      "23603/23603 [==============================] - 2s 93us/step - loss: 25.9805 - tip_accuracy: 0.7194 - val_loss: 27.1549 - val_tip_accuracy: 0.7089\n",
      "Epoch 16/20\n",
      "23603/23603 [==============================] - 2s 100us/step - loss: 25.9114 - tip_accuracy: 0.7197 - val_loss: 27.2595 - val_tip_accuracy: 0.7067\n",
      "Epoch 17/20\n",
      "23603/23603 [==============================] - 2s 92us/step - loss: 25.8309 - tip_accuracy: 0.7211 - val_loss: 27.2912 - val_tip_accuracy: 0.7072\n",
      "Epoch 18/20\n",
      "23603/23603 [==============================] - 2s 94us/step - loss: 25.8039 - tip_accuracy: 0.7188 - val_loss: 27.2164 - val_tip_accuracy: 0.7039\n",
      "Epoch 19/20\n",
      "23603/23603 [==============================] - 2s 92us/step - loss: 25.7636 - tip_accuracy: 0.7215 - val_loss: 27.2729 - val_tip_accuracy: 0.7048\n",
      "Epoch 20/20\n",
      "23603/23603 [==============================] - 2s 97us/step - loss: 25.7210 - tip_accuracy: 0.7248 - val_loss: 27.4073 - val_tip_accuracy: 0.7070\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "/usr/local/lib/python3.6/site-packages/tensorflow/python/ops/gradients_impl.py:108: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error</th>\n",
       "      <th>model</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.746154</td>\n",
       "      <td>29.457558</td>\n",
       "      <td>avg</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.720513</td>\n",
       "      <td>30.330299</td>\n",
       "      <td>avg_nn</td>\n",
       "      <td>2011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.774272</td>\n",
       "      <td>28.045074</td>\n",
       "      <td>avg</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.762136</td>\n",
       "      <td>29.374311</td>\n",
       "      <td>avg_nn</td>\n",
       "      <td>2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.714976</td>\n",
       "      <td>26.830137</td>\n",
       "      <td>avg</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.736715</td>\n",
       "      <td>27.436588</td>\n",
       "      <td>avg_nn</td>\n",
       "      <td>2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.724638</td>\n",
       "      <td>28.777830</td>\n",
       "      <td>avg</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.736715</td>\n",
       "      <td>29.294245</td>\n",
       "      <td>avg_nn</td>\n",
       "      <td>2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.716019</td>\n",
       "      <td>30.183555</td>\n",
       "      <td>avg</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.733010</td>\n",
       "      <td>30.013413</td>\n",
       "      <td>avg_nn</td>\n",
       "      <td>2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.724638</td>\n",
       "      <td>28.026182</td>\n",
       "      <td>avg</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.748792</td>\n",
       "      <td>27.996376</td>\n",
       "      <td>avg_nn</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    accuracy      error   model  year\n",
       "0   0.746154  29.457558     avg  2011\n",
       "1   0.720513  30.330299  avg_nn  2011\n",
       "2   0.774272  28.045074     avg  2012\n",
       "3   0.762136  29.374311  avg_nn  2012\n",
       "4   0.714976  26.830137     avg  2013\n",
       "5   0.736715  27.436588  avg_nn  2013\n",
       "6   0.724638  28.777830     avg  2014\n",
       "7   0.736715  29.294245  avg_nn  2014\n",
       "8   0.716019  30.183555     avg  2015\n",
       "9   0.733010  30.013413  avg_nn  2015\n",
       "10  0.724638  28.026182     avg  2016\n",
       "11  0.748792  27.996376  avg_nn  2016"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "YEAR_ESTIMATORS = [\n",
    "    ('avg', avg_model, {}),\n",
    "    ('avg_nn',\n",
    "     nn_pipe,\n",
    "     {'kerasregressor__callbacks': [callbacks.EarlyStopping(monitor='val_loss', patience=3)],\n",
    "      'kerasregressor__verbose': 0})\n",
    "]\n",
    "\n",
    "year_scores = yearly_performance_scores(YEAR_ESTIMATORS, features, labels, parallel=False, data_frame=True)\n",
    "year_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4oAAAIPCAYAAAA1hyAnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAIABJREFUeJzs3Xu4XVV5L+DfhwFDAkEwgDcgVRC5Y4tVoVTqpcELKKWKxQDaVoq2pVhL60FUmnpsraU9ekQKtoWKKaACoqigPUBRW0WooiIXBQGBFgIokAANkHH+mCtxz80O2Un2Xjsk7/s868laY4415jfXWmh+GXOOWa21AAAAwDIbTHUBAAAArF0ERQAAAHoERQAAAHoERQAAAHoERQAAAHoERQAAAHoERQCSJFX15qpqVbXfar5/v8H73zyxlQEAwyYoAqwFRoSsVlUfXUGfrapqyaDPpUMuEQBYjwiKAGuXh5IcWlVPHmPbYUkqySPDLQkAWN8IigBrl/OSbJ7ktWNse0uSLyb5n6FWRE91NpnqOtYWVbXpVNcAwMQTFAHWLv+Z5LvpQuFyVfXLSXZJctqK3lhVr6uqr1fV4qpaNHg+VuBMVb21qq6tqv+pqh9V1THpZivH6rtZVX1w0O9/qmphVZ1ZVc9e3YOsqmdU1YlV9Z2q+mlVPVRVP6iqP6uqJ43Rf6Oq+tNB/weq6t6quqKq/mBUv1lV9b+r6prBmHdX1deq6o0j+lxaVTeNsY85g9N6TxjRtvy6y6r6/ar6QbpZ3z8ZbP/lqjq9qq4f1HX/4HM/aAXH/bSq+khV3Tj4LO+sqq9U1SsG288fjDNrjPe+YFDLe1fy2S671vTlVXVCVd082Nd3R34Oo96zV1WdV1V3DfpeV1Xvrqppo/pdWlU3VdWzq+ozVXVPkvtWUs8WVfV3VXXDiO/kyqo6doy+hwy+r/sHn8M3q+o3V9Dvc1V1y6Deu6rqs1W1+xh9966qL1XVfw/2f1tVfbGqXjSq35yqOqOq7hiMeUNVfaCqZozqd8Lg891xsP3WQf+rqupVj/dZADyRTFt5FwCG7J+S/G1VPbO1dtug7beT3JnkgrHeUFVvT3JSkmuTzB80vznJZ6vq91prp47oe0ySv0tyVZLjksxIF3zuHGPczZL8e5JtB3VdneTpSd6e5JtVtVdr7ebVOMbdk/xGuhnUG5JsmGT/JH+V5NlJfm9EDRsluSjJfkm+nOST6cLaboMxPjro95QkX0sXqD+T5OQkT0ry/CSvSXLWatS5zDFJnprk40n+O8lPBu0HJXlekk8luXnQ54gk51bVm1pr/zLiOOYk+XqSrZN8IskVSWYmeVGSlyf5ymD8A5P8VpJTRtXwO0mWpvsexuODg/E/Nnj9liRnVtX01trpI+p6dZJzk/woyYlJ7kny4nS/oz2TvH7UuJsk+bfBsbw7yVYrqePTSX41yd+n+0eQjZPslO77/NCIOt4/GO/CJO8ZHOtBST5dVX/QWjtpxJh/kOTuJKem+z6ek+TIJF+vql9srf1wMOaO6T7X/07y4SR3pPv8fyXJHkm+Mei3XZLLk2w2+Lx+OKjvfyXZp6pe1lobfcr3Pyd5OMnfJNko3W/ks1X13NbaTSv5TADWfq01Dw8PD48pfqT7S2lLF9iemu700uMG2zZO8rMkfzN4vSjJpSPeu/mg7UdJZo1on5UuhN2f5CmDtqckWZzkB0lmjOj7rMEYLcl+I9o/nOTBJHuMqne7dDNJp49xDG8ex/FunKTGaD8jyaNJnj6i7U8H435gjP4bjHj+sUG/I1fS79IkN43RZ87g/SeMcUz3JNlqjPfMHKNtRpLrkvxgVPsXB2PNXVF96YLtLUkuH2PMe5N8cRyf7ZsH+7k5yWYj2jcbtN2TZONB2/R0IeqyJNNGjfOOMX4Plw7a3j/O3/Vmg/4fW0m/X3yc7/izg9/apiv53HdK99/Nx0a0HT0Y95dXsv8Fg36vGtX+oUH774xoO2HQdsHI33CSFwza/3I8n42Hh4fH2v5w6inAWqa1dneSz6X7C3/SzZptlhXPJL0i3czRR1pry08DHDz/SLoZoJcPmn89Xeg4qbX2wIi+t6b7y/JyVVVJ3pQuRNxWVbOXPdKFzW8MxludY3ywtdYG+9locHri7HQzhxsk2WtE9zcl+Wl+PlM6cpylgzE2SPLGJNe0EbOno/utgU+01h4z49paW7zseVXNqKqnpvt8L06y07JTSKtqi3Qzphe21i5aUX2ttUfTfc8vqKrdRnT5zXTB/x9XoeaTW2v3jtjHvelm9TZPF4CT7rezdbpTmp8y6jv+4qDPWN/x34yzhgfThbcXDmZUV+RN6ULWP4+sYVDH55Jsmm6Wc9mxLE6WXy86a9BvYbqA/sIR4y47/tdW1fSxdjz47RyY5NuttS+O2vyX+fnM5mgfXvYbHtT0rXT/2LLD4xwnwBOGU08B1k6nJflCVf1KutNOL2+t/WAFfX9h8OfVY2xb1vbsUX9eO0bf0eNvmW5289fT/SV8LKsVwAbXvr0ryeFJts9jr4/cfMTzHZJ8p7X20OMMOXvwngtXp55xuH6sxqraKsn70y0+NNYpmE9JNxu27Bi/PY59/WOS49OdanrMoO130p0a/LlVqPmaMdqWfcfLfgc7Df58vNNZtx71emFr7WfjKaC1tmRwqvOHk/y4ums8L07y2dba/xvRdad0n89Yv8vH1FFVz0/yF+kC78xR/X484vlZSealO8X6HVX1jXT/GHFW+/kp01um+8eUx/z301q7p6r+Kz//vEa6cYy2u9P9NwPwhCcoAqydLkpyW5L3Jfm1JG+bghqWhbd/TXe920T62yR/mOTsJP87XQh6ON0piB/M5C621lbQ/nj/n/jA6IbBjOuX04WcD6e75vDedKfOviXJoVmN42it/aSqLkwyr6r+NN1pvr+a7tTjh1d1vJVY9h0fm+Q7K+hz+6jXj/ksHk9r7e+r6vwkr07yknSzo39QVWe31pYtrlPpvpdXpvv8xnJ1klTVtulmue9LFxavSzfD3ZL8n3Shb9m+/yfJK6pbDGpuus9xfpITqurQ1tp5q3Iso6yozjEXhQJ4ohEUAdZCrbVHq+oT6RbTeDDJmY/TfdnMxi5J/t+obTuP6rPsz+c9Tt9lFqa7NnJWa+1fx1n6eB2W5LIRQSFJUlXbj9H3+iTPq6onD/7iP5a70p2eusc49n1Pkl8ao31VV3HdfbC/+a21943cUFW/O6rvj9IFmT3HOfap6YLV69ItxpOs2mmnSRdgzx/VNvr38MPBn4sn4TterrX2X0n+Ick/VLeq7RlJfquqThycsvnDdKfm3tJaG2smdKSD0oXBA1trl4zcMDj19zG/kdba5ekWq0lVbZNuZvf96RZTWpjuOt5dRr+vqjZPt3jTikI0wDrLNYoAa6+/T/LnSY4aee3hGL6SbkblD2vEPe0Gz/8w3XVTXxnR98Ekvz9y2f+qela6GbDlBtfNLUjyy2PdomDwvpWteLkij2bUzEtVzUy3gMpoC9KdVnr8GPuvEbWemWTnqvqdFfUbuD7JpoNZpmXbN1jBvld2DMljj2PXjLqmrbV2T5IvJXllVb08o4yqL0m+kG4m7/fSraL69dba452WOZa3DVatXbaPzZIclS78/9ug+aJ0s7nvGlxHObqujWsN7pM4uG6zd3uJwXWY3x28XLbPMwZ/fqDGvj3KyNNfV/S5vzXJ00a1zR6jrFvThcMtBvUsTfL5JM+vqv1H9X1Xur8rrcnMI8ATkhlFgLVUa+2WdCssrqzfzwanKJ6U7pYVpw82vTndtXG/t2xRk9baT6vqPekWI/n3wazljHQB4of5+ezVMu9Osk+ST1XVp9ItYLMk3emQr0pyZX6+6M6q+EyS36uqs9Od2rp1umsx7x6j74eTHJDk+Kp6QbrTPR9KNwO0Y36+UM/xSV6abtbq19PdKqMGxzQt3Sxm0s3WvTPJeVX14cHx/GZW/f8Tr0l3OuSfDsLQdUmemy7cfS+PnbX8g3S3GvlSVf1zus9u43SLr9yU5M+WdRzMKP9Tfh6Oj1vF2pJulvWbVbXs3ptvSXebk99dtpBRa21xVR2ebmXR6wb7/FG6ayufl24hpYPSrXa6Op6b5N+q6rwk308367tTulOpf5zkq4M6vlXd/StPSPKdqvp0uqD89HSf46vS3YIi6QL3A0nOqKqPDsbcZ9DnhvS/x+MHv4ULBvurdL+l5yX56xH9jku3sM9nq+pjg8/gV5Mcku40139ezeMHeMISFAHWAa21jw0W3Tg23XWNSXefxINaa58d1ffEqlqU5I/Trer4k3TB8d6MWtSktXZvVe2TLli9Id2iLY+km5X5WrrTCVfHH6c73W/ZmD9JF+C+lS44jqxhyeAv++9MN+v5gXRB8YfpFv1Z1u+nVfXidH/pXxZw7k+3gMv/HdHvx1X1usE4f5EunJ4xOPZxz9oNwtyr0312R6RbVOX7g+d7ZFRQHOx3r3T3CHxVuoV8fprue3rMSq3pPtvj0s0Wf3q8dY3wZ0n2TfL76YL49Ul693Yc1HXRIIC/K93CL1sO6roh3bWk383q+0m6z/XX0p1G++R0195+PMkHR628++dVdUW6W1ock+7zvDPdZ3r0iH43VNUr031/x6WbYfx6uusfP5ruNifLfDZd2HzD4DN4MN3v5q0ZcSpva+3mqnphuusX56ULyrem++/j/e2x91AEWOfViJWdAYC1RFU9PV3Q+sfW2u+twvvenC5A/1pr7dLJqQ6AdZ1rFAFg7fS2JE/K2LONADCpnHoKAGuRqnpjumsJj01yUWvtyikuCYD1kKAIAGuXM9Ndg/nVJI9ZwRUAhsE1igAAAPS4RhEAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAIAeQREAAICeaVNdwDDNnj27zZkzZ6rLAAAAmBJXXnnlXa21LVfWb70KinPmzMkVV1wx1WUAAABMiaq6eTz9nHoKAABAj6AIAABAj6AIAABAj6AIAABAj6AIAABAz3q16ikAADCxli5dmrvuuis/+9nP8uijj051Oeu1Jz3pSXnKU56S2bNnZ4MN1mxOUFAEAABW26233pqqypw5c7Lhhhumqqa6pPVSay0PP/xw7rjjjtx6663Zdttt12g8p54CAACrbfHixXnmM5+ZjTbaSEicQlWVjTbaKM985jOzePHiNR5PUAQAANbImp7myMSZqO/CNwoAAECPoAgAAECPxWwAAIAJ9UvHfmKo+7vyQ4cPdX/rAzOKAAAA9AiKAAAA9AiKAADAeufCCy/Mvvvum8033zxbbLFF5s6dm2uuuSZJsvfee+ed73xnr/99992XjTfeOOeee26S5I477siBBx6YjTfeONttt11OO+207LrrrjnhhBOGfSiTYqhBsaq2qKrzqmpxVd1cVYeuoN+Tq+rvq+qOqrqnqj5fVc9c1XEAAADGsnjx4hxzzDG5/PLLc+mll2azzTbLAQcckCVLlmTevHk566yzsnTp0uX9zznnnEyfPj2vfvWrkyRHHHFEbr755lx88cU5//zz88lPfjI333zzVB3OhBv2YjYnJVmSZOskeyb5QlVd1Vq7elS/P0ry4iS7J7k3yalJ/m+S31jFcQAAAB7j4IMP7r0+7bTTMmvWrFx++eU55JBDcswxx+SSSy7Jy172siTJggUL8vrXvz5PfvKTc9111+Wiiy7Kf/zHf+RFL3pRkuT000/PnDlzhn0Yk2ZoM4pVNTPJwUne01pb1Fr7WpLPJTlsjO6/kOSi1todrbWHkpydZJfVGAcAAOAxbrjhhhx66KF5znOek1mzZmXrrbfO0qVLc8stt+SpT31q9t9//yxYsCBJcvvtt+eSSy7JvHnzkiTXXnttNthgg+y1117Lx9tmm23yjGc8Y0qOZTIM89TT5yZ5pLV2/Yi2qzIIgKP8Y5J9quoZVTUjyZuSfGk1xgEAAHiM17zmNVm4cGFOOeWUfPOb38y3v/3tTJs2LUuWLEmSzJs3L+ecc04eeuihnHXWWdlmm22y7777TnHVwzPMoLhJkvtGtd2bZNMx+v4wyU+S3DZ4z05J5q/GOKmqI6vqiqq6YuHChatZOgAAsK64++67c+211+a4447Ly1/+8uy00065//7788gjjyzvc+CBByZJLrjggixYsCCHHnpoqipJ8rznPS9Lly7NlVdeubz/rbfemttvv324BzKJhhkUFyWZNaptVpL7x+h7UpInJ3lqkplJzs3PZxRXZZy01k5tre3VWttryy23XM3SAQCAdcXmm2+e2bNn5+Mf/3h+9KMf5d/+7d9y1FFHZdq0ny/hMn369Bx88MF5//vfn//8z/9cftppkuy4446ZO3dujjrqqHzjG9/Id77znbzlLW/JjBkzlofJJ7phLmZzfZJpVbVDa+2Hg7Y9koy1AM2eSd7dWrsnSarq/yaZX1WzV3EcAABgyK780OFTXcLj2mCDDXL22Wfn6KOPzq677prtt98+J5544mMWuJk3b15OO+20PP/5z8/OO+/c23b66afnrW99a/bbb79stdVWmT9/fm688cZMnz59mIcyaYYWFFtri6vq3HSB73fThcHXJtl7jO7fSnJ4VV2a5IEkb09ye2vtriRZhXEAAAAe46UvfWm+//3v99oWLVr0mD6ttTHf/7SnPS2f//znl7++6667cuSRR2b77bef+GKnwFDvo5gu8G2c5M4kZyZ5W2vt6qrat6pGfit/kuShdNcqLkzyqiQHrWycIdQPAACw/P6JN954Y77xjW/kkEMOyezZs7P//vtPdWkTYqj3URycSvq6Mdq/mm6RmmWv70630ukqjQMAADAMDz/8cI4//vjceOONmTFjRl70ohflsssuy8yZM6e6tAkx1KAIAACwLpg7d27mzp071WVMmmGfegoAAMBaTlAEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgx+0xAACACXXL/N2Gur9t3/u9oe5vfWBGEQAAgB5BEQAAgB5BEQAAWO9ceOGF2XfffbP55ptniy22yNy5c3PNNdckSfbee++8853v7PW/7777svHGG+fcc89Nktxxxx058MADs/HGG2e77bbLaaedll133TUnnHDCuPZfVTn11FPz+te/PjNnzsyzn/3sfPKTn1y+/aabbkpV5ZxzzskrXvGKzJgxIzvvvHO+8pWvTMwHsBKCIgAAsN5ZvHhxjjnmmFx++eW59NJLs9lmm+WAAw7IkiVLMm/evJx11llZunTp8v7nnHNOpk+fnle/+tVJkiOOOCI333xzLr744px//vn55Cc/mZtvvnmVapg/f35e+9rX5qqrrsohhxyS3/7t384tt9zS6/Pud787Rx99dK666qq84AUvyBvf+MYsWrRozT+AlRAUAQCA9c7BBx+cgw8+ODvssEN23333nHbaafnxj3+cyy+/PIccckgWLlyYSy65ZHn/BQsW5PWvf32e/OQn57rrrstFF12UU045JS9+8Yuz55575vTTT88DDzywSjUcdthhmTdvXrbffvv8xV/8RaZNm5bLLrus1+cd73hHDjjggOywww75wAc+kHvuuSff+c53JuQzeDyCIgAAsN654YYbcuihh+Y5z3lOZs2ala233jpLly7NLbfckqc+9anZf//9s2DBgiTJ7bffnksuuSTz5s1Lklx77bXZYIMNstdeey0fb5tttskznvGMVaph9913X/582rRp2XLLLXPnnXeusM+y8Uf3mQyCIgAAsN55zWtek4ULF+aUU07JN7/5zXz729/OtGnTsmTJkiTJvHnzcs455+Shhx7KWWedlW222Sb77rvvhNaw4YYb9l5XVe9019F9qipJHtNnMgiKAADAeuXuu+/Otddem+OOOy4vf/nLs9NOO+X+++/PI488srzPgQcemCS54IILsmDBghx66KHLg9rznve8LF26NFdeeeXy/rfeemtuv/324R7IJJo21QUAAAAM0+abb57Zs2fn4x//eLbZZpvcdtttOfbYYzNt2s/j0fTp03PwwQfn/e9/f6666qqcccYZy7ftuOOOmTt3bo466qicfPLJmT59eo499tjMmDFjeZh8ohMUAQCACbXte7831SU8rg022CBnn312jj766Oy6667Zfvvtc+KJJ+bggw/u9Zs3b15OO+20PP/5z8/OO+/c23b66afnrW99a/bbb79stdVWmT9/fm688cZMnz59mIcyaQRFAABgvfPSl7403//+93tto2878dKXvjSttTHf/7SnPS2f//znl7++6667cuSRR2b77bcf1/7HGvemm25a/nzOnDlj9llRPRNNUAQAAFhFF198ce6///7stttuufPOO/Pud787s2fPzv777z/VpU0Ii9kAAACsoocffjjHH398dttttxxwwAGZMWNGLrvsssycOTMLFizIJptsMuZjl112merSx8WMIgAAwCqaO3du5s6dO+a2Aw88MC984QvH3Db6lhhrK0ERAABgAm266abZdNNNp7qMNeLUUwAAYI0Ma4EVVm6ivgtBEQAAWG0bbrhhHnzwwakug4EHH3xwQk5vFRQBAIDVttVWW+W2227LAw88YGZxCrXW8sADD+S2227LVltttcbjuUYRAABYbbNmzUqS3H777Xn44YenuJr124Ybbpitt956+XeyJgRFAABgjcyaNWtCwglrD6eeAgAA0CMoAgAA0CMoAgAA0CMoAgAA0CMoAgAA0CMoAgAA0CMoAgAA0CMoAgAA0CMoAgAA0DNtqguAdckvHfuJqS5hUl35ocOnugQAAIbAjCIAAAA9giIAAAA9giIAAAA9giIAAAA9giIAAAA9giIAAAA9giIAAAA9giIAAAA9giIAAAA9giIAAAA9giIAAAA9giIAAAA9giIAAAA9giIAAAA9giIAAAA9giIAAAA9giIAAAA9giIAAAA9giIAAAA906a6AOCJ45b5u011CZNq2/d+b6pLAABYK5hRBAAAoEdQBAAAoEdQBAAAoEdQBAAAoEdQBAAAoEdQBAAAoEdQBAAAoEdQBAAAoEdQBAAAoEdQBAAAoEdQBAAAoEdQBAAAoEdQBAAAoEdQBAAAoEdQBAAAoGeoQbGqtqiq86pqcVXdXFWHrqDfl6pq0YjHkqr63ojtN1XVgyO2f3l4RwEAALBumzbk/Z2UZEmSrZPsmeQLVXVVa+3qkZ1aa68c+bqqLk1y8aixDmit/esk1goAALBeGtqMYlXNTHJwkve01ha11r6W5HNJDlvJ++Yk2TfJJya7RgAAAIZ76ulzkzzSWrt+RNtVSXZZyfsOT/LV1tpNo9oXVNXCqvpyVe0xgXUCAACs14YZFDdJct+otnuTbLqS9x2e5PRRbW9KMifJdkkuSXJRVT1lrDdX1ZFVdUVVXbFw4cJVrRkAAGC9M8yguCjJrFFts5Lcv6I3VNWvJHlaks+MbG+tfb219mBr7YHW2l8m+Vm601Mfo7V2amttr9baXltuueUaHQAAAMD6YJiL2VyfZFpV7dBa++GgbY8kVz/Oe45Icm5rbdFKxm5JagJqBAAA1gG3zN9tqkuYVNu+93sr77QGhjaj2FpbnOTcJPOramZV7ZPktUnOGKt/VW2c5A0ZddppVW1bVftU1UZVNb2qjk0yO8nXJ/UAAAAA1hNDvY9ikrcn2TjJnUnOTPK21trVVbVvVY2eNXxdulNKLxnVvmmSk5P8NMltSfZP8srW2t2TWjkAAMB6Yqj3UWyt3ZMuAI5u/2q6xW5Gtp2ZLkyO7nt1kt0nq0YAAID13VCD4hPVLx277t7C8coPHT7VJQAAAGuZYZ96CgAAwFpOUAQAAKBHUAQAAKBHUAQAAKBHUAQAAKBHUAQAAKBHUAQAAKBHUAQAAKBHUAQAAKBHUAQAAKBHUAQAAKBHUAQAAKBHUAQAAKBHUAQAAKBHUAQAAKBn2lQXAMC655b5u011CZNq2/d+b6pLWKf4vQCsfcwoAgAA0CMoAgAA0CMoAgAA0CMoAgAA0CMoAgAA0GPVUwAAnhCskAvDY0YRAACAHkERAACAHkERAACAHkERAACAHkERAACAHkERAACAHkERAACAHkERAACAHkERAACAHkERAACAHkERAACAHkERAACAHkERAACAnmlTXQAA8Ph+6dhPTHUJk+q8Tae6Alg/+d8WHo8ZRQAAAHoERQAAAHoERQAAAHoERQAAAHoERQAAAHqserqeu2X+blNdwqTa9r3fm+oSAADgCceMIgAAAD2CIgAAAD2CIgAAAD2CIgAAAD2CIgAAAD2CIgAAAD2CIgAAAD3uowgAsA75pWM/MdUlTJrzNp3qCmD9YUYRAACAHjOKAFPEv/oDAGsrM4oAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0CIoAAAD0DDUoVtUWVXVeVS2uqpur6tAV9PtSVS0a8VhSVd8bsX1OVV1SVQ9U1bVV9fLhHQUAAMC6bdqQ93dSkiVJtk6yZ5IvVNVVrbWrR3Zqrb1y5OuqujTJxSOazkzyH0leNXh8pqp2aK0tnMTaAQAA1gtDm1GsqplJDk7yntbaotba15J8LslhK3nfnCT7JvnE4PVzk/xikve11h5srZ2T5HuDsQEAAFhDwzz19LlJHmmtXT+i7aoku6zkfYcn+Wpr7abB612S3Nhau38841TVkVV1RVVdsXChCUcAAICVGWZQ3CTJfaPa7k2y6Ured3iS00eNc+94x2mtndpa26u1tteWW245/moBAADWU+MKilX1f6pq1zXc16Iks0a1zUpy/xh9l+33V5I8Lcln1mQcAAAAxm+8M4ovSHJVVV0+OJVzZbOAY7k+ybSq2mFE2x5Jrl5B/yQ5Ism5rbVFI9olvqV3AAAXQUlEQVSuTvLsUTWsbBwAAADGaVxBsbW2T5Kdk1yS5H1J/quqPlFVLxnvjlpri5Ocm2R+Vc2sqn2SvDbJGWP1r6qNk7wh/dNOM7jG8TtJ3ldV06vqoCS7JzlnvLUAAACwYuO+RrG1dl1r7c+SbJPkjemuFfxyVf2wqt5VVVuMY5i3J9k4yZ3pbnHxttba1VW1b1UtGtX3dUl+li6cjvbGJHsl+WmSv0rym26NAQAAMDFW5z6KG6a7JnCzJE9Kcku6W1wcX1VHttb+ZUVvbK3dky4Ajm7/arrgObLtzHRhcqxxbkqy32rUDgAAwEqMe0axqvaqqo8l+a8kf53kG0l2aK29rLW2S5Jjk/zd5JQJAADAsIxrRrGqvpdkxyQXJXlzki+01h4d1e3TSU6a0OoAAAAYuvGeevqpJP/UWrttRR1aa3dluPdlBAAAYBKMNyh+MGOEwKqanmRpa23JhFYFAADAlBnvDOCn061YOtpR6WYbAQAAWEeMNyjuk+TLY7R/JcneE1cOAAAAU228QXFGkkfGaF+aZNOJKwcAAICpNt6g+N0kvzVG+6FJvj9x5QAAADDVxruYzfwk51fV9kkuHrS9LMnrkxw0GYUBAAAwNcY1o9ha+2KSA5Jsl+Qjg8e2SQ5srV0weeUBAAAwbOOdUUxr7cIkF05iLQAAAKwFxnuNIgAAAOuJcQXFqtqoqv68qq6vqoeq6tGRj8kuEgAAgOEZ74ziXyQ5IsmJ6W6JcWySk5LcneTtk1MaAAAAU2G8QfENSY5qrZ2S5NEk57fWjk7yviSvmKziAAAAGL7xBsWtk/xg8HxRkqcMnl+Y5NcnuigAAACmzniD4i1JnjF4/qMkcwfPX5zkwYkuCgAAgKkz3qB4XpKXDZ5/OMmfV9WPk5ye5B8moS4AAACmyLjuo9ha+18jnn+mqn6SZJ8k17fWLpis4gAAABi+lQbFqtowySeTHNdauyFJWmvfTPLNSa4NAACAKbDSU09baw+nW7CmTX45AAAATLXxXqN4bpLfmMxCAAAAWDuM6xrFdKueHl9V+ya5IsnikRtba3870YUBAAAwNcYbFN+c5KdJdh88RmpJBEUAAIB1xHhXPf2FyS4EAACAtcN4r1EEAABgPTGuGcWq+sjjbW+tHT0x5QAAADDVxnuN4m6jXm+Y5HlJnpTk2xNaEQAAAFNqvNco/trotqqanuQfk3x1oosCAABg6qz2NYqttYeSfCDJuyeuHAAAAKbami5mMzvJJhNRCAAAAGuH8S5m88ejm5I8PcmbknxxoosCAABg6ox3MZs/HPV6aZKFSU5L8pcTWhEAAABTaryL2fzCZBcCAADA2mFc1yhW1UaDVU5Ht0+vqo0mviwAAACmyngXs/l0kreP0X5Ukk9NXDkAAABMtfEGxX2SfHmM9q8k2XviygEAAGCqjTcozkjyyBjtS5NsOnHlAAAAMNXGGxS/m+S3xmg/NMn3J64cAAAAptp4b48xP8n5VbV9kosHbS9L8vokB01GYQAAAEyNcc0otta+mOSAJNsl+cjgsW2SA1trF0xeeQAAAAzbeGcU01q7MMmFk1gLAAAAa4Hx3kfxJVX1khW0/+rElwUAAMBUGe9iNn+XZPMx2mcNtgEAALCOGG9Q3DHJVWO0f3+wDQAAgHXEeIPig0mePkb7M5MsmbhyAAAAmGrjDYoXJflgVS0//bSqtkjyl4NtAAAArCPGu+rpnyS5LMlNVfXdQdvuSRYmOWQyCgMAAGBqjPc+iv+VZI90gfG7g8c7k+yWZOdJqw4AAIChW5X7KD6Q5ONJUlXPTPKWdIvZzEnypMkoDgAAgOEb7zWKqaonVdVvVNUXktyU5KAkpyTZfpJqAwAAYAqsdEaxqnZM8rtJDk+yOMm/JJmb5LDW2g8mtzwAAACG7XFnFKvqq0m+kWTzJG9orT27tXZ8kjaM4gAAABi+lc0ovjjJSUlOba1dPYR6AAAAmGIru0bxBenC5Neq6ttV9Y6qetoQ6gIAAGCKPG5QbK19u7X2+0menuRvkxyY5CeD9726qjaf/BIBAAAYpvHeR/Gh1toZrbVfS7JTkg8leUeS/66qL01mgQAAAAzXuG+PsUxr7UettXcl2SbJG5IsmfCqAAAAmDIrvT3GirTWHk1y/uABAADAOmKVZxQBAABYtwmKAAAA9AiKAAAA9AiKAAAA9AiKAAAA9AiKAAAA9AiKAAAA9AiKAAAA9AiKAAAA9AiKAAAA9AiKAAAA9AiKAAAA9AiKAAAA9AiKAAAA9Aw1KFbVFlV1XlUtrqqbq+rQx+n7i1V1WVUtqqo7quqPRmy7qaoeHGxbVFVfHs4RAAAArPumDXl/JyVZkmTrJHsm+UJVXdVau3pkp6qaneTCJO9I8pkkGyV51qixDmit/evklwwAALB+GdqMYlXNTHJwkve01ha11r6W5HNJDhuj+x8nuai1tqC19j+ttftba9cMq1YAAID12TBPPX1ukkdaa9ePaLsqyS5j9H1Rknuq6t+r6s6q+nxVbTuqz4KqWlhVX66qPVa006o6sqquqKorFi5cuOZHAQAAsI4bZlDcJMl9o9ruTbLpGH2fleSIJH+UZNskP05y5ojtb0oyJ8l2SS5JclFVPWWsnbbWTm2t7dVa22vLLbdcowMAAABYHwwzKC5KMmtU26wk94/R98Ek57XWvtVaeyjJnyfZu6o2S5LW2tdbaw+21h5orf1lkp8l2XcSawcAAFhvDDMoXp9kWlXtMKJtjyRXj9H3u0naiNdtjD4Ztb3WrDwAAACSIQbF1triJOcmmV9VM6tqnySvTXLGGN1PS3JQVe1ZVRsmeU+Sr7XW7q2qbatqn6raqKqmV9WxSWYn+fqwjgUAAGBdNtT7KCZ5e5KNk9yZ7prDt7XWrq6qfatq0bJOrbWLkxyX5AuDvtsnWXbPxU2TnJzkp0luS7J/kle21u4e2lEAAACsw4Z6H8XW2j1JXjdG+1fTLXYzsu3kdIFwdN+rk+w+WTUCAACs74Y9owgAAMBaTlAEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgR1AEAACgZ6hBsaq2qKrzqmpxVd1cVYc+Tt9frKrLqmpRVd1RVX80Ytucqrqkqh6oqmur6uXDOQIAAIB137BnFE9KsiTJ1knelOTkqtpldKeqmp3kwiSnJHlqku2TfHlElzOTfHuw7d1JPlNVW05u6QAAAOuHoQXFqpqZ5OAk72mtLWqtfS3J55IcNkb3P05yUWttQWvtf1pr97fWrhmM89wkv5jkfa21B1tr5yT53mBsAAAA1tAwZxSfm+SR1tr1I9quSvKYGcUkL0pyT1X9e1XdWVWfr6ptB9t2SXJja+3+cYwDAADAKhpmUNwkyX2j2u5NsukYfZ+V5Igkf5Rk2yQ/Tne66bJx7h3nOKmqI6vqiqq6YuHChatZOgAAwPpjmEFxUZJZo9pmJbl/jL4PJjmvtfat1tpDSf48yd5VtdkqjpPW2qmttb1aa3ttuaXLGAEAAFZmmEHx+iTTqmqHEW17JLl6jL7fTdJGvB75/Ookz66qkTOIKxoHAACAVTS0oNhaW5zk3CTzq2pmVe2T5LVJzhij+2lJDqqqPatqwyTvSfK11tq9g2scv5PkfVU1vaoOSrJ7knOGcyQAAADrtmHfHuPtSTZOcme6aw7f1lq7uqr2rapFyzq11i5OclySLwz6bp9k5D0X35hkryQ/TfJXSX6zteYCRAAAgAkwbZg7a63dk+R1Y7R/Nd0iNSPbTk5y8grGuSnJfhNfIQAAAMOeUQQAAGAtJygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQIygCAADQM9SgWFVbVNV5VbW4qm6uqkNX0O+Eqnq4qhaNeDx7xPY2GGPZtn8Y3lEAAACs26YNeX8nJVmSZOskeyb5QlVd1Vq7eoy+Z7fW5j3OWHu01n40GUUCAACsz4Y2o1hVM5McnOQ9rbVFrbWvJflcksOGVQMAAAArV6214eyo6vlJvt5amzGi7U+SvKS1dsCovickeUeSR5P8V5KPttZOHrG9Ddo3SPLvSf64tXbTCvZ7ZJIjBy93THLdBB3SumJ2krumugieMPxeGC+/FVaF3wvj5bfCqvB7Gdt2rbUtV9ZpmKeebpLkvlFt9ybZdIy+n0pyapI7krwwyTlV9bPW2pmD7S9J8o0kM5K8P8kFVbVna+2R0QO11k4djMUYquqK1tpeU10HTwx+L4yX3wqrwu+F8fJbYVX4vayZYS5msyjJrFFts5LcP7pja+0HrbXbW2uPttb+PcmHk/zmiO2XtdaWtNZ+luSPkvxCkp0mr3QAAID1xzCD4vVJplXVDiPa9kgy1kI2o7UktQbbAQAAGKehBcXW2uIk5yaZX1Uzq2qfJK9NcsbovlX12qravDq/nOToJOcPtu1SVXtW1ZOqapMkJya5Lck1wzqWdYzTclkVfi+Ml98Kq8LvhfHyW2FV+L2sgaEtZpN091FM8k9JXpHk7iTvaq39S1Xtm+RLrbVNBv3OTPLrSZ6c5NYkH2utfWSw7aVJTk7yrCSL0y1mc2xr7YdDOxAAAIB12FCDIgAAAGu/YV6jCAAAwBOAoAgAAECPoAgAAECPoEiSZLDC7K9OdR2sXapq8xW0P2vYtbB2q6oNqmr2iNe7DVawftpU1sUTQ1V9pKo2neo6WLsN/ndml6rataqeNNX1sPaoqllVtdGI1y+rqhMHj/2msLQnNEGRZTZKcslUF8HaoaqeW1XXJLm7qm6rqjeM6vKDqaiLtVNV7Z1kYZI7qurvq+qwJGcn+Zsk1w1uhwSpqt8e65HksCS/M3gOSZKqOnXE8+2SXJXkm0n+I8n3q+o5U1Uba51LkmyfJFX19iRnJtkwybQkZ1fV705hbU9YVj1dj1TV4Y+zeaMkp7TW/AsdqaovJflWkr9L8pIkH03y0dbaXw22399a86//JEmq6utJ/jrJ0iSfTXJoa+3swbY/S7J/a+3XprBE1hJV9f/bu5tQuc46juPfv8ammCaWNihIjRSttEqNIBiVLqRuRERoRTArqeJCqrhUKQhu7FJdKC7EliKIUvFtVSgFXxFfFsYWglaL2lrUGtsYUlu9+bk455Y7yU37PCEz54Tz/UAgMwfCn/C9d+aZ85wzZ4AHGb4ia6e3A78Cnkly88YH0yxV1ckkB8a/3ws8DnwCKIbv0T6U5NYJR9RMnNXKceD9SX47Pr4B+EGS104546XIheKCVNUW8Gvgmd0OA29zoSiAqnoCeEWSrfHxNcB9wHeT3OFCUTtV1YkkV1VVAf8B9id5djx2OfBokoPP+49oEcYPLD8NfDHJV3Y8/zhwOMnfJxtOs7Pztaaq/gpcn+Tk+PgK4OEkbm8XVfUYcCTJo+Pvk1fveB26DPin71v67Zl6AG3U74FPJjlni+n4Zu705kfSTJ0B9gNPAoy/eN8B3Od1RNrFGYAkqarj2y/Ooy2G7T8SSe6pqu8Dd1bVL4Dbk/xy6rk0X1V1LcOlUmdYfZ9yGtg3yVCao7uAu6vqIwy7ob5UVZ8dj90B/GSyyS5hXqO4LD8Erj/Psa3xuATwM+CWnU8k+QdwM/BW4KVTDKXZOl5V1wEkOXzWsbcAj2x+JM1VkieTfBT4GPDlqvoqw+UP0tn2AQ8zfND9SobXn203Ao9NMZRm6TPAz4FjwKeADwN/Gv/cAHj98wVw66mkc4xv+q/c7ZP+8YziLUnu2fxkmqOquho4leScbe1VdQTYm+RHm59Mc1dVLwJuZ/gQ6oPb2wqlF1JVr2e4RMIb8ek5VXUlw4cI1wBPA8eS/HHaqS5dLhQlSZIkSSvceioAqmpPVX1t6jk0f7aiHvaiVraiHvaiVrZy4TyjKACqai9w2rue6oXYinrYi1rZinrYi1rZyoXzrqcLUlUPPM9hf3j0HFtRD3tRK1tRD3tRK1tZDxeKy3IEuJPhC2vP9hLgps2OoxmzFfWwF7WyFfWwF7WylTVw6+mCVNVPgc8nuXeXY3uBp5N43apsRV3sRa1sRT3sRa1sZT38D1uWLwAnznPsv8BtG5xF82Yr6mEvamUr6mEvamUra+AZRUmSJEnSCq9RXKCqeh3wBmA/8G/goSS/m3YqzZGtqIe9qJWtqIe9qJWtXFyeUVyQqjoEfBM4DPwBeAo4ALwG+A3wgSR/nm5CzYWtqIe9qJWtqIe9qJWtrIfXKC7LXcCPgYNJbkxyU5I3Ai8fn797yuE0K7aiHvaiVraiHvaiVrayBp5RXJCqOgVcleTZXY7tBU4k2bf5yTQ3tqIe9qJWtqIe9qJWtrIenlFclr8A7znPsXcDnpLXNltRD3tRK1tRD3tRK1tZA88oLkhVvRP4NvAgw37t7f3bb2K48Pd9SR6YbkLNha2oh72ola2oh72ola2shwvFhamqq4FbGX5orgBOAQ8B30nyxJSzaV5sRT3sRa1sRT3sRa1s5eJzobgw412h3swutwuuqqNJvjHNZJobW1EPe1ErW1EPe1ErW7n4XCguSFW9C/gW8AhwHcMdoD6eZGs8fjLJgekm1FzYinrYi1rZinrYi1rZynp4M5tl+RxwNMlh4FqGH6TvVdVl4/GabDLNja2oh72ola2oh72ola2sgWcUF6Sqnkrysh2P9wBfBw4C7wX+lmT/VPNpPmxFPexFrWxFPexFrWxlPTyjuCz/qqpXbT9I8j/gKMMtg+8HXjzVYJodW1EPe1ErW1EPe1ErW1kDF4rLcj9w284nMvgQcAy4fJKpNEe2oh72ola2oh72ola2sgZuPV2QcZ/2niSnz3P8UBK/kFS2oi72ola2oh72ola2sh4uFCVJkiRJK9x6KkmSJEla4UJRkiRJkrTChaIkSZIkaYULRUmSJEnSCheKkiRJkqQV/wdKQraliotToQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "graph_yearly_model_performance(year_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>0.733449</td>\n",
       "      <td>28.553390</td>\n",
       "      <td>2013.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_nn</th>\n",
       "      <td>0.739647</td>\n",
       "      <td>29.074205</td>\n",
       "      <td>2013.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy      error    year\n",
       "model                              \n",
       "avg     0.733449  28.553390  2013.5\n",
       "avg_nn  0.739647  29.074205  2013.5"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_scores.groupby('model').mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>error</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>0.022927</td>\n",
       "      <td>1.185855</td>\n",
       "      <td>1.870829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_nn</th>\n",
       "      <td>0.014260</td>\n",
       "      <td>1.135066</td>\n",
       "      <td>1.870829</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        accuracy     error      year\n",
       "model                               \n",
       "avg     0.022927  1.185855  1.870829\n",
       "avg_nn  0.014260  1.135066  1.870829"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "year_scores.groupby('model').std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple avg model performs a little better\n",
    "The yearly accuracy for the model with the NN is a little better, but the basic avg model performs better across all other metrics and has a much faster training time, so I'll leave out the NN for now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
